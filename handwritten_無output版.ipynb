{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "UC6muen3T7ot",
        "eVNpZpR0NjHS",
        "oPAZ5huhRZaw"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOgt9WKmOL3ZcRnbwiaIHMV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anny4608/Mathematical-Analysis-to-Data-Science_SVD_HW2/blob/master/handwritten_%E7%84%A1output%E7%89%88.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##載入套件"
      ],
      "metadata": {
        "id": "Yt-XhKHRZkkL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pC_pyxBNHd0o"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "import math\n",
        "from scipy.io import loadmat\n",
        "import h5py"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kaggle API\n"
      ],
      "metadata": {
        "id": "B1lVD3BgT2NI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 載入Kaggle 套件跟API\n",
        "\n",
        "!pip install -q kaggle\n",
        "\n",
        "from google.colab import files\n",
        "import json\n",
        "import os\n",
        "\n",
        "print(\"上傳 kaggle.json\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# 確認有沒有設定成功\n",
        "!kaggle config view"
      ],
      "metadata": {
        "id": "D55ESG15H9XF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 下載資料集"
      ],
      "metadata": {
        "id": "BskK8XJMT47Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p data/usps\n",
        "!kaggle datasets download -d bistaumanga/usps-dataset -p data/usps --unzip\n",
        "\n",
        "# 檢查下載的檔案\n",
        "print(\"\\n=== USPS資料集內容 ===\")\n",
        "!ls -la data/usps/"
      ],
      "metadata": {
        "id": "vy_oPtmNIlxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 處理USPS資料集\n"
      ],
      "metadata": {
        "id": "UC6muen3T7ot"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.先檢查原始的資料結構\n"
      ],
      "metadata": {
        "id": "NdwJhRHpHuf5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 首先檢查資料結構\n",
        "with h5py.File('/content/data/usps/usps.h5', 'r') as hf:\n",
        "    # 查看檔案結構\n",
        "    print(\"H5檔案的主要類別:\")\n",
        "    print(list(hf.keys()))\n",
        "\n",
        "    # 檢查訓練資料\n",
        "    train = hf.get('train')\n",
        "    print(\"\\n訓練資料集包含:\")\n",
        "    print(list(train.keys()))\n",
        "\n",
        "    x_train = train.get('data')[:]\n",
        "    y_train = train.get('target')[:]\n",
        "\n",
        "    # 檢查測試資料\n",
        "    test = hf.get('test')\n",
        "    print(\"\\n測試資料集包含:\")\n",
        "    print(list(test.keys()))\n",
        "\n",
        "    x_test = test.get('data')[:]\n",
        "    y_test = test.get('target')[:]"
      ],
      "metadata": {
        "id": "LOSrH-j0aT91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 顯示詳細的資料形狀資訊\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"USPS Dataset：\")\n",
        "print(\"=\"*50)\n",
        "print(f\"訓練資料形狀: {x_train.shape}\")\n",
        "print(f\"訓練標籤形狀: {y_train.shape}\")\n",
        "print(f\"訓練標籤維度數: {y_train.ndim}\")\n",
        "print(f\"訓練標籤前10個值: {y_train[:10]}\")\n",
        "print(f\"\\n測試資料形狀: {x_test.shape}\")\n",
        "print(f\"測試標籤形狀: {y_test.shape}\")\n",
        "print(f\"測試標籤維度數: {y_test.ndim}\")\n",
        "print(f\"測試標籤前10個值: {y_test[:10]}\")\n",
        "\n",
        "# 檢查標籤的唯一值\n",
        "print(f\"\\n標籤的唯一值: {np.unique(y_train)}\")\n",
        "print(f\"影像維度: 16x16 像素 (256個特徵)\")"
      ],
      "metadata": {
        "id": "oytwbwjDJDyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 顯示datasets每個數字類別的範例\n",
        "fig, axes = plt.subplots(2, 5, figsize=(12, 6))\n",
        "fig.suptitle(\"USPS Datasets _ 0-9's example \", fontsize=16)\n",
        "\n",
        "for digit in range(10):\n",
        "    # 找到第一個屬於該數字的影像\n",
        "    indices = np.where(y_train == digit)[0]\n",
        "    if len(indices) > 0:\n",
        "        idx = indices[0]\n",
        "\n",
        "        # 決定子圖位置\n",
        "        row = digit // 5\n",
        "        col = digit % 5\n",
        "\n",
        "        # 顯示影像\n",
        "        img = x_train[idx].reshape(16, 16)\n",
        "        axes[row, col].imshow(img, cmap='gray')\n",
        "        axes[row, col].set_title(f'Digit: {digit}')\n",
        "        axes[row, col].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xwFDY0z2Jo5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 顯示訓練集的前20個影像\n",
        "fig, axes = plt.subplots(4, 5, figsize=(12, 10))\n",
        "fig.suptitle('USPS Training datasets ', fontsize=16)\n",
        "\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    if i < len(x_train):\n",
        "        # 將影像重新形狀為 16x16\n",
        "        img = x_train[i].reshape(16, 16)\n",
        "\n",
        "        # 顯示影像\n",
        "        ax.imshow(img, cmap='gray')\n",
        "\n",
        "        # 獲取標籤（假設 y_train 是直接的標籤值）\n",
        "        label = int(y_train[i])\n",
        "        ax.set_title(f'Digit: {label}')\n",
        "        ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "J-M5RDYrauEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.為了後續方便 將資料集轉換成白底黑字"
      ],
      "metadata": {
        "id": "TzJTB-HTHzlB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 轉換成白底黑字\n",
        "\n",
        "import h5py\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# 讀取資料\n",
        "with h5py.File('/content/data/usps/usps.h5', 'r') as hf:\n",
        "    train = hf.get('train')\n",
        "    x_train = train.get('data')[:]\n",
        "    y_train = train.get('target')[:]\n",
        "    test = hf.get('test')\n",
        "    x_test = test.get('data')[:]\n",
        "    y_test = test.get('target')[:]\n",
        "\n",
        "# 建立資料夾結構\n",
        "for digit in range(10):\n",
        "    os.makedirs(f'usps_inverted/train/{digit}', exist_ok=True)\n",
        "    os.makedirs(f'usps_inverted/test/{digit}', exist_ok=True)\n",
        "\n",
        "print(\"開始轉換訓練資料為白底黑字...\")\n",
        "# 儲存反轉的training sets影像\n",
        "for i in range(min(7291, len(x_train))):\n",
        "    img_array = x_train[i].reshape(16, 16)\n",
        "    img_inverted = 1.0 - img_array  # 反轉顏色（1 - 原始值）\n",
        "    img_inverted_255 = (img_inverted * 255).astype(np.uint8) # 轉換到 0-255 範圍\n",
        "    img = Image.fromarray(img_inverted_255, mode='L')\n",
        "    img_large = img.resize((160, 160), Image.NEAREST)\n",
        "    label = int(y_train[i])\n",
        "    img_large.save(f'usps_inverted/train/{label}/train_{i:05d}.png')\n",
        "\n",
        "    if i % 200 == 0:\n",
        "        print(f\"  已處理 {i}/7291 張訓練影像\")\n",
        "\n",
        "# 儲存反轉的testing sets影像\n",
        "for i in range(min(2007, len(x_test))):\n",
        "    img_array = x_test[i].reshape(16, 16)\n",
        "    img_inverted = 1.0 - img_array\n",
        "    img_inverted_255 = (img_inverted * 255).astype(np.uint8)\n",
        "    img = Image.fromarray(img_inverted_255, mode='L')\n",
        "    img_large = img.resize((160, 160), Image.NEAREST)\n",
        "    label = int(y_test[i])\n",
        "    img_large.save(f'usps_inverted/test/{label}/test_{i:05d}.png')\n",
        "\n",
        "    if i % 100 == 0:\n",
        "        print(f\"  已處理 {i}/2007 張測試影像\")\n",
        "\n",
        "print(\"\\n轉換完成！白底黑字的影像已儲存到 usps_inverted/ 資料夾\")"
      ],
      "metadata": {
        "id": "I7cm29ZYS5K7",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 確認轉換後的資料量\n",
        "import os\n",
        "def count_files(path):\n",
        "    total = 0\n",
        "    for root, dirs, files in os.walk(path):\n",
        "        total += len(files)\n",
        "    return total\n",
        "\n",
        "test_count = count_files('usps_inverted/test')\n",
        "train_count = count_files('usps_inverted/train')\n",
        "\n",
        "print(f'test: {test_count}')\n",
        "print(f'train: {train_count}')\n",
        "print(f'總計: {test_count + train_count}')"
      ],
      "metadata": {
        "id": "rk4YJsKSLn7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "base_dir = \"usps_inverted\"   # 根目錄名稱\n",
        "splits = [\"train\", \"test\"]   # 要顯示的資料集\n",
        "classes = [str(i) for i in range(10)]  # 0~9\n",
        "\n",
        "fig, axes = plt.subplots(len(splits), len(classes), figsize=(15, 4))\n",
        "fig.suptitle('USPS Training-Testing datasets after inverted ', fontsize=16)\n",
        "\n",
        "for i, split in enumerate(splits):\n",
        "    for j, cls in enumerate(classes):\n",
        "        folder = os.path.join(base_dir, split, cls)\n",
        "        files = sorted(os.listdir(folder))  # 該類別資料夾中的檔案列表\n",
        "        if not files:\n",
        "            continue  # 若空資料夾就跳過\n",
        "        img_path = os.path.join(folder, files[0])  # 取第一張\n",
        "\n",
        "        img = Image.open(img_path)\n",
        "        axes[i, j].imshow(img, cmap=\"gray\")  # 若是灰階圖，用 cmap=\"gray\"\n",
        "        axes[i, j].set_title(f\"{split}-{cls}\")\n",
        "        axes[i, j].axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "2Drq9GeHT8vM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 設定資料路徑\n",
        "TRAIN_PATH = 'usps_inverted/train'\n",
        "TEST_PATH = 'usps_inverted/test'"
      ],
      "metadata": {
        "id": "pJa6KIxeUtVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 建立自己的測試資料集"
      ],
      "metadata": {
        "id": "u3wUWw1RTug8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 建立自己寫的數字的資料集 然後手動上傳圖片\n",
        "!mkdir -p handwrite/mine\n",
        "!mkdir -p handwrite/dr"
      ],
      "metadata": {
        "id": "P8LCrfrKliMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 方法一 :Mean"
      ],
      "metadata": {
        "id": "eVNpZpR0NjHS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 載入資料的函數\n",
        "def load_usps_data(base_path, img_size=(16, 16)):\n",
        "\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    print(f\"正在載入資料從: {base_path}\")\n",
        "\n",
        "    # 讀取每個數字資料夾 (0-9)\n",
        "    for digit in range(10):\n",
        "        digit_path = os.path.join(base_path, str(digit))\n",
        "\n",
        "        if os.path.exists(digit_path):\n",
        "            img_files = os.listdir(digit_path)\n",
        "            print(f\"  數字 {digit}: 找到 {len(img_files)} 張圖片\")\n",
        "\n",
        "            for filename in img_files:\n",
        "                if filename.endswith(('.png', '.jpg', '.jpeg')):\n",
        "                    img_path = os.path.join(digit_path, filename)\n",
        "                    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "                    if img is not None:\n",
        "                        # 確保圖片大小一致\n",
        "                        if img.shape != img_size:\n",
        "                            img = cv2.resize(img, img_size)\n",
        "\n",
        "                        # 正規化到 [0, 1]\n",
        "                        img = img.astype(np.float32) / 255\n",
        "\n",
        "                        # 展平成一維向量\n",
        "                        images.append(img.flatten())\n",
        "                        labels.append(digit)\n",
        "\n",
        "    return np.array(images), np.array(labels)"
      ],
      "metadata": {
        "id": "Ka0Lg3XWebWZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. 載入訓練和測試資料\n",
        "print(\"=\" * 50)\n",
        "print(\"載入資料集...\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "x_train, y_train = load_usps_data(TRAIN_PATH)\n",
        "x_test, y_test = load_usps_data(TEST_PATH)\n",
        "\n",
        "print(f\"\\n訓練集: {x_train.shape[0]} 張圖片\")\n",
        "print(f\"測試集: {x_test.shape[0]} 張圖片\")\n",
        "print(f\"圖片維度: {x_train.shape[1]} (16x16 展平)\")"
      ],
      "metadata": {
        "id": "FlcLhsyqeltt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. 計算每個數字的平均模板\n",
        "def calculate_mean_templates(x_train, y_train):\n",
        "    \"\"\"\n",
        "    計算每個數字的平均模板\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    print(\"計算平均模板...\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    mean_templates = {}\n",
        "\n",
        "    for digit in range(10):\n",
        "        # 找出屬於該數字的所有訓練樣本\n",
        "        digit_samples = x_train[y_train == digit]\n",
        "\n",
        "        if len(digit_samples) > 0:\n",
        "            # 計算平均值\n",
        "            mean_template = np.mean(digit_samples, axis=0)\n",
        "            mean_templates[digit] = mean_template\n",
        "            print(f\"數字 {digit}: 使用 {len(digit_samples)} 個樣本計算平均模板\")\n",
        "\n",
        "    return mean_templates\n",
        "\n",
        "mean_templates = calculate_mean_templates(x_train, y_train)"
      ],
      "metadata": {
        "id": "xnpyh1clerVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for digit in range(10):\n",
        "    template = mean_templates[digit]          # 這是一個長度 256 的 1D 向量\n",
        "    template_2d = template.reshape(16, 16)    # 轉成 16x16\n",
        "\n",
        "    print(f\"\\n=== 數字 {digit} 的平均模板值 (16x16) ===\")\n",
        "    print(template_2d)"
      ],
      "metadata": {
        "id": "5xdWwgSzY6sq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for digit in range(10):\n",
        "    t = mean_templates[digit]\n",
        "    print(f\"數字 {digit}: 形狀 {t.shape}, min={t.min():.4f}, max={t.max():.4f}, mean={t.mean():.4f}\")"
      ],
      "metadata": {
        "id": "fun011t6ZDfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 定義 2-norm 計算函數(也可以寫成老師的版本z、mi帶入a、ak)一樣意思\n",
        "def norm2(z, mi):\n",
        "\n",
        "    return np.linalg.norm(z - mi, 2)"
      ],
      "metadata": {
        "id": "nuR2bZyHftpT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. 建立基於 2-norm 的分類器\n",
        "class Norm2Classifier:\n",
        "    def __init__(self, mean_templates):\n",
        "        self.mean_templates = mean_templates\n",
        "\n",
        "    def classify(self, sample): ##使用 2-norm 進行分類 選擇距離最小的模板作為預測結果\n",
        "\n",
        "        min_distance = float('inf')\n",
        "        predicted_digit = -1\n",
        "        all_distances = {}\n",
        "\n",
        "        for digit, template in self.mean_templates.items():\n",
        "            distance = norm2(sample, template)\n",
        "            all_distances[digit] = distance\n",
        "\n",
        "            if distance < min_distance:\n",
        "                min_distance = distance\n",
        "                predicted_digit = digit\n",
        "\n",
        "        return predicted_digit, min_distance, all_distances\n",
        "\n",
        "    def predict_batch(self, X_test):\n",
        "\n",
        "        predictions = []\n",
        "        min_distances = []\n",
        "        all_distances_list = []\n",
        "\n",
        "        for sample in X_test:\n",
        "            pred, min_dist, all_dist = self.classify(sample)\n",
        "            predictions.append(pred)\n",
        "            min_distances.append(min_dist)\n",
        "            all_distances_list.append(all_dist)\n",
        "\n",
        "        return np.array(predictions), np.array(min_distances), all_distances_list\n"
      ],
      "metadata": {
        "id": "7_JbLLfWfubT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. 進行分類預測\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"使用 2-norm 進行分類預測...\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "classifier = Norm2Classifier(mean_templates)\n",
        "predictions, distances, all_distances_list = classifier.predict_batch(x_test)\n"
      ],
      "metadata": {
        "id": "r7tlk-kzf3rb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. 評估結果\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "accuracy = accuracy_score(y_test,predictions)\n",
        "conf_matrix = confusion_matrix(y_test,predictions)\n",
        "\n",
        "print(f\"\\n===== 2-norm 方法評估結果 =====\")\n",
        "print(f\"整體準確率: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
        "print(f\"正確分類: {np.sum(predictions == y_test)} / {len(y_test)}\")\n",
        "print(f\"錯誤分類: {np.sum(predictions != y_test)} / {len(y_test)}\")\n",
        "\n",
        "print(\"\\n==========分類報告:==========\")\n",
        "print(classification_report(y_test,predictions))"
      ],
      "metadata": {
        "id": "hrIst8fKf7t4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_norm2_results():\n",
        "    plt.rcParams['font.size'] = 14\n",
        "\n",
        "    fig = plt.figure(figsize=(18, 10), dpi=180)\n",
        "\n",
        "    print(\"\\n繪製視覺化結果...\")\n",
        "\n",
        "    # 1. 顯示mean再重組後的數字的模板\n",
        "    for i in range(10):\n",
        "        plt.subplot(5, 10, i+1)\n",
        "        template = mean_templates[i].reshape(16, 16)\n",
        "        plt.imshow(template, cmap='gray')\n",
        "        plt.title(f'Mean {i}', fontsize=16)\n",
        "        plt.axis('off')\n",
        "\n",
        "    fig.suptitle('Mean Templates with 2-norm Method',\n",
        "                 fontsize=22, weight='bold', y=0.97)\n",
        "\n",
        "    # 2. 正確分類\n",
        "    correct_idx = np.where(predictions == y_test)[0][:10]\n",
        "    for idx, i in enumerate(correct_idx):\n",
        "        plt.subplot(5, 10, 11+idx)\n",
        "        img = x_test[i].reshape(16, 16)\n",
        "        plt.imshow(img, cmap='gray')\n",
        "        plt.title(f'✓{y_test[i]}\\n2-norm:{distances[i]:.2f}',\n",
        "                  color='green', fontsize=14)\n",
        "        plt.axis('off')\n",
        "\n",
        "    # 3. 錯誤分類\n",
        "    wrong_idx = np.where(predictions != y_test)[0][:10]\n",
        "    for idx, i in enumerate(wrong_idx):\n",
        "        if idx < len(wrong_idx):\n",
        "            plt.subplot(5, 10, 21+idx)\n",
        "            img = x_test[i].reshape(16, 16)\n",
        "            plt.imshow(img, cmap='gray')\n",
        "            true_norm = norm2(x_test[i], mean_templates[y_test[i]])\n",
        "            plt.title(f'{y_test[i]}→{predictions[i]}\\n2-norm:{distances[i]:.2f}',\n",
        "                      color='red', fontsize=14)\n",
        "            plt.axis('off')\n",
        "\n",
        "    # 4. 最小 2-norm\n",
        "    sorted_idx = np.argsort(distances)[:10]\n",
        "    for idx, i in enumerate(sorted_idx):\n",
        "        plt.subplot(5, 10, 31+idx)\n",
        "        img = x_test[i].reshape(16, 16)\n",
        "        plt.imshow(img, cmap='gray')\n",
        "        plt.title(f'Pred:{predictions[i]}\\n2-norm:{distances[i]:.3f}',\n",
        "                  color='blue', fontsize=14)\n",
        "        plt.axis('off')\n",
        "\n",
        "    # 5. 最大 2-norm\n",
        "    sorted_idx_max = np.argsort(distances)[-10:][::-1]\n",
        "    for idx, i in enumerate(sorted_idx_max):\n",
        "        plt.subplot(5, 10, 41+idx)\n",
        "        img = x_test[i].reshape(16, 16)\n",
        "        plt.imshow(img, cmap='gray')\n",
        "        plt.title(f'Pred:{predictions[i]}\\n2-norm:{distances[i]:.3f}',\n",
        "                  color='orange', fontsize=14)\n",
        "        plt.axis('off')\n",
        "\n",
        "    # 左側行標籤\n",
        "    fig.text(0.03, 0.80, 'Mean', rotation=90, va='center',\n",
        "             fontsize=14, color='gray', weight='bold')\n",
        "    fig.text(0.03, 0.60, 'Correct', rotation=90, va='center',\n",
        "             fontsize=14, color='green', weight='bold')\n",
        "    fig.text(0.03, 0.45, 'Wrong', rotation=90, va='center',\n",
        "             fontsize=14, color='red', weight='bold')\n",
        "    fig.text(0.03, 0.30, 'Min 2-norm', rotation=90, va='center',\n",
        "             fontsize=14, color='blue', weight='bold')\n",
        "    fig.text(0.03, 0.15, 'Max 2-norm', rotation=90, va='center',\n",
        "             fontsize=14, color='orange', weight='bold')\n",
        "\n",
        "    plt.tight_layout(rect=[0.06, 0.03, 0.98, 0.93])\n",
        "    plt.savefig('norm2_results.png', dpi=180, bbox_inches='tight')\n",
        "    plt.show()\n",
        "visualize_norm2_results()"
      ],
      "metadata": {
        "id": "4PWAlVLBWvuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. 繪製mean平均法的混淆矩陣\n",
        "def visualize_confusionMatrix_results():\n",
        "\n",
        "    plt.figure(figsize=(20, 12))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=range(10), yticklabels=range(10))\n",
        "    plt.title(f'Confusion Matrix - Mean Method\\nAccuracy: {accuracy:.2%}',\n",
        "              fontsize=14, weight='bold')\n",
        "    plt.xlabel('Predicted Label', fontsize=12)\n",
        "    plt.ylabel('True Label', fontsize=12)\n",
        "    plt.savefig('Confusion_matrix_MeanbyNorm2.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "visualize_confusionMatrix_results()"
      ],
      "metadata": {
        "id": "3hSk2J2ocOB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_digit_confusion(digit, x_test, y_test, mean_templates):\n",
        "\n",
        "    # 找出所有該數字的測試樣本\n",
        "    digit_indices = np.where(y_test == digit)[0]\n",
        "\n",
        "    print(f\"\\n分析數字 {digit} 的混淆情況 (共 {len(digit_indices)} 個樣本)\")\n",
        "\n",
        "    # 計算每個樣本到所有模板的距離\n",
        "    all_distances = []\n",
        "    for idx in digit_indices:\n",
        "        distances_to_templates = []\n",
        "        sample = x_test[idx]\n",
        "\n",
        "        for template_digit in range(10):\n",
        "            dist = norm2(sample, mean_templates[template_digit])\n",
        "            distances_to_templates.append(dist)\n",
        "\n",
        "        all_distances.append(distances_to_templates)\n",
        "\n",
        "    # 繪製距離分佈圖\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    for distances in all_distances:\n",
        "        plt.plot(range(10), distances, alpha=0.3, color='blue')\n",
        "\n",
        "    # 繪製平均距離\n",
        "    avg_distances = np.mean(all_distances, axis=0)\n",
        "    plt.plot(range(10), avg_distances, 'r-', linewidth=3, label='mean distance')\n",
        "    print(f\"\\nAvg distances for digit {digit} =\", avg_distances)\n",
        "\n",
        "\n",
        "    plt.xlabel('Mean number template', fontsize=12)\n",
        "    plt.ylabel('2-Norm ', fontsize=12)\n",
        "    plt.title(f'No. {digit} to every templates distance ', fontsize=14, fontweight='bold')\n",
        "    plt.xticks(range(10))\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.show()\n",
        "\n",
        "    # 找出最容易混淆的數字\n",
        "    avg_distances[digit] = np.inf  # 排除自己\n",
        "    confused_with = np.argmin(avg_distances)\n",
        "    print(f\"數字 {digit} 最容易被誤判為: {confused_with}\")\n",
        "    print(f\"到正確模板的平均距離: {np.mean([d[digit] for d in all_distances]):.4f}\")\n",
        "    print(f\"到混淆模板的平均距離: {avg_distances[confused_with]:.4f}\")\n",
        "\n",
        "# 使用範例\n",
        "analyze_digit_confusion(0, x_test, y_test, mean_templates)  ##最好的前兩個\n",
        "analyze_digit_confusion(1, x_test, y_test, mean_templates)\n",
        "analyze_digit_confusion(4, x_test, y_test, mean_templates)  ##最爛的兩個\n",
        "analyze_digit_confusion(6, x_test, y_test, mean_templates)"
      ],
      "metadata": {
        "id": "xJNZAMWp1rP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "對某個 digit（例如 0）\n",
        "\n",
        "把所有屬於 0 的樣本取出\n",
        "\n",
        "計算 對 0~9 每一個 mean template 的距離（L2 norm）\n",
        "\n",
        "每張圖都會畫一條藍線\n",
        "\n",
        "紅線是所有跟平均法出來的板模的距離後總和的\"平均距離\"\n",
        "\n",
        "--\n",
        "\n",
        "藍線跟紅線距離最短的地方 → 該預測的數字\n",
        "\n",
        "線第二低的地方 → 最容易混淆的數字\n",
        "\n",
        "線高的地方 → 長得最不像的數字"
      ],
      "metadata": {
        "id": "HpSlBS_WppbH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 方法一:Mean_自己手寫預測"
      ],
      "metadata": {
        "id": "oPAZ5huhRZaw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.手寫字_原始版(無框ROI+無字體加粗)"
      ],
      "metadata": {
        "id": "dXtA69WzQO91"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def load_handwrite_original(folder_path, img_size=(16, 16)):\n",
        "    images = []\n",
        "    names = []\n",
        "\n",
        "    print(f\"\\n從 {folder_path} 載入並處理圖片...\")\n",
        "\n",
        "    for filename in sorted(os.listdir(folder_path)):\n",
        "        if not filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "            continue\n",
        "\n",
        "        img_path = os.path.join(folder_path, filename)\n",
        "\n",
        "        # 0. 讀取灰階\n",
        "        gray = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "        if gray is None:\n",
        "            continue\n",
        "\n",
        "        # 1. 自動判斷是否需要反轉\n",
        "        mean_val = np.mean(gray)\n",
        "        if mean_val < 128:          # 平均偏暗，視為黑底白字\n",
        "            gray = 255 - gray       # 反轉成白底黑字（淺背景、深字）\n",
        "\n",
        "        # 2. 直接把整張灰階圖縮放到指定大小\n",
        "        digit_small = cv2.resize(\n",
        "            gray, img_size,\n",
        "            interpolation=cv2.INTER_AREA\n",
        "        )\n",
        "\n",
        "        # # 3.做一點對比拉伸，讓數字更黑、背景更白\n",
        "        # digit_enhanced = cv2.normalize(\n",
        "        #     digit_small, None, alpha=0, beta=255,\n",
        "        #     norm_type=cv2.NORM_MINMAX\n",
        "        # )\n",
        "\n",
        "        # 4. 正規化到 [0, 1]\n",
        "        img_normalized = digit_small.astype(np.float32) / 255.0\n",
        "\n",
        "        # 5. flatten 成 1D 向量\n",
        "        images.append(img_normalized.flatten())\n",
        "        names.append(filename)\n",
        "\n",
        "        print(f\"  ✓ 處理: {filename}\")\n",
        "\n",
        "    images = np.array(images)\n",
        "    print(f\"共載入 {len(images)} 張圖片\\n\")\n",
        "    return images, names\n"
      ],
      "metadata": {
        "id": "NRNES3EqIWYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def visualize_preprocessing(folder_path, n_samples=10, img_size=(16, 16)):\n",
        "\n",
        "    files = sorted([\n",
        "        f for f in os.listdir(folder_path)\n",
        "        if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
        "    ])[:n_samples]\n",
        "\n",
        "    # 每張圖顯示 4 個步驟\n",
        "    fig, axes = plt.subplots(n_samples, 4, figsize=(12, 3 * n_samples))\n",
        "    if n_samples == 1:\n",
        "        axes = axes.reshape(1, -1)\n",
        "\n",
        "    fig.suptitle(f'{folder_path}_Image preprocessing steps', fontsize=18, fontweight='bold')\n",
        "\n",
        "    for idx, filename in enumerate(files):\n",
        "        img_path = os.path.join(folder_path, filename)\n",
        "        gray = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        if gray is None:\n",
        "            continue\n",
        "\n",
        "        # 1. 原始圖片\n",
        "        axes[idx, 0].imshow(gray, cmap='gray')\n",
        "        axes[idx, 0].set_title('1. original img')\n",
        "        axes[idx, 0].axis('off')\n",
        "\n",
        "        # 2. 自動反轉 → 確保是「白底黑字」\n",
        "        if np.mean(gray) < 128:\n",
        "            inv = 255 - gray   # 原本偏暗，視為黑底白字 → 反轉\n",
        "        else:\n",
        "            inv = gray.copy()  # 原本就白底黑字，不動\n",
        "\n",
        "        axes[idx, 1].imshow(inv, cmap='gray')\n",
        "        axes[idx, 1].set_title('2. auto invert\\n(white bg, dark digit)')\n",
        "        axes[idx, 1].axis('off')\n",
        "\n",
        "        # 3. 整張縮放到 img_size，並做對比拉伸\n",
        "        digit_small = cv2.resize(\n",
        "            inv, img_size,\n",
        "            interpolation=cv2.INTER_AREA\n",
        "        )\n",
        "\n",
        "        # 這裡就是模型要吃的 16x16 灰階\n",
        "        axes[idx, 2].imshow(digit_small, cmap='gray')\n",
        "        axes[idx, 2].set_title(f'3. resize + normalize\\n({img_size[0]}x{img_size[1]})')\n",
        "        axes[idx, 2].axis('off')\n",
        "\n",
        "        # 4. 放大顯示（只是放大，不改變數值）\n",
        "        disp = cv2.resize(\n",
        "            digit_small, (64, 64),\n",
        "            interpolation=cv2.INTER_NEAREST\n",
        "        )\n",
        "        axes[idx, 3].imshow(disp, cmap='gray')\n",
        "        axes[idx, 3].set_title('4. zoom out\\n(real img_size)')\n",
        "        axes[idx, 3].axis('off')\n",
        "\n",
        "\n",
        "    plt.tight_layout(rect=[0.0, 0, 1, 0.99])\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "visualize_preprocessing('handwrite/dr', n_samples=10, img_size=(16, 16))\n",
        "visualize_preprocessing('handwrite/mine', n_samples=10, img_size=(16, 16))\n"
      ],
      "metadata": {
        "id": "pXWRyatke0Ef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 使用load_handwrite_original\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"使用load_handwrite_original處理重新預測\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# 1) 醫師的手寫\n",
        "X_dr_enhanced, dr_names = load_handwrite_original('handwrite/dr')\n",
        "dr_preds_new, dr_dists_new, _ = classifier.predict_batch(X_dr_enhanced)\n",
        "\n",
        "print(\"\\n=== handwrite/dr 預測結果 ===\")\n",
        "for name, pred, dist in zip(dr_names, dr_preds_new, dr_dists_new):\n",
        "    print(f\"檔名: {name:>6s} -> 預測數字: {pred} (最小距離: {dist:.4f})\")\n",
        "\n",
        "# 2) 我的手寫\n",
        "X_mine_enhanced, mine_names = load_handwrite_original('handwrite/mine')\n",
        "mine_preds_new, mine_dists_new, _ = classifier.predict_batch(X_mine_enhanced)\n",
        "\n",
        "print(\"\\n=== handwrite/mine 預測結果 ===\")\n",
        "for name, pred, dist in zip(mine_names, mine_preds_new, mine_dists_new):\n",
        "    print(f\"檔名: {name:>6s} -> 預測數字: {pred} (最小距離: {dist:.4f})\")\n"
      ],
      "metadata": {
        "id": "HgNMyNJjOmsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dr_correct = sum(\n",
        "    int(name.split('.')[0]) == int(pred)\n",
        "    for name, pred in zip(dr_names, dr_preds_new)\n",
        ")\n",
        "\n",
        "print(f\"dr 正確 {dr_correct} / {len(dr_names)}\")\n",
        "\n",
        "mine_correct = sum(\n",
        "    int(name.split('.')[0]) == int(pred)\n",
        "    for name, pred in zip(mine_names, mine_preds_new)\n",
        ")\n",
        "\n",
        "print(f\"mine 正確 {mine_correct} / {len(mine_names)}\")\n"
      ],
      "metadata": {
        "id": "zH9jill2gjZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.手寫字_無框ROI+字體加粗"
      ],
      "metadata": {
        "id": "eR63Px1vP8b8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def load_handwrite_enhanced(folder_path, img_size=(16, 16)):\n",
        "\n",
        "    images = []\n",
        "    names = []\n",
        "\n",
        "    print(f\"\\n從 {folder_path} 載入並增強圖片...\")\n",
        "\n",
        "    for filename in sorted(os.listdir(folder_path)):\n",
        "        if not filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "            continue\n",
        "\n",
        "        img_path = os.path.join(folder_path, filename)\n",
        "\n",
        "        # 0. 讀取灰階\n",
        "        gray = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "        if gray is None:\n",
        "            continue\n",
        "\n",
        "        # 1. 自動判斷是否需要反轉\n",
        "        mean_val = np.mean(gray)\n",
        "        if mean_val < 128:          # 平均偏暗，視為黑底白字\n",
        "            gray = 255 - gray       # 反轉成白底黑字（淺背景、深字）\n",
        "\n",
        "        # 2. 直接把整張灰階圖縮放到指定大小 (例如 16x16)\n",
        "        digit_small = cv2.resize(\n",
        "            gray, img_size,\n",
        "            interpolation=cv2.INTER_AREA\n",
        "        )\n",
        "\n",
        "        # 3. 在 16x16 灰階圖上做「反轉 + 膨脹 + 再反轉」來加粗深色筆劃\n",
        "        inv_small = 255 - digit_small              # 深色數字 → 變亮\n",
        "        kernel = np.ones((2, 2), np.uint8)\n",
        "        inv_thick = cv2.dilate(inv_small, kernel, iterations=1)\n",
        "        digit_thick_gray = 255 - inv_thick         # 反轉回深色數字\n",
        "\n",
        "        # 4. 做一點對比拉伸，讓數字更黑、背景更白\n",
        "        digit_thick_gray = cv2.normalize(\n",
        "            digit_thick_gray, None, alpha=0, beta=255,\n",
        "            norm_type=cv2.NORM_MINMAX\n",
        "        )\n",
        "\n",
        "        # 5. 正規化到 [0, 1]\n",
        "        img_normalized = digit_thick_gray.astype(np.float32) / 255.0\n",
        "\n",
        "        # 6. flatten 成 1D 向量\n",
        "        images.append(img_normalized.flatten())\n",
        "        names.append(filename)\n",
        "\n",
        "        print(f\"  ✓ 處理: {filename}\")\n",
        "\n",
        "    images = np.array(images)\n",
        "    print(f\"共載入 {len(images)} 張圖片\\n\")\n",
        "    return images, names\n"
      ],
      "metadata": {
        "id": "SuONzxyiIV2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def visualize_preprocessing(folder_path, n_samples=10, img_size=(16, 16)):\n",
        "\n",
        "    files = sorted([\n",
        "        f for f in os.listdir(folder_path)\n",
        "        if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
        "    ])[:n_samples]\n",
        "\n",
        "    # 每張圖顯示 4 個步驟\n",
        "    fig, axes = plt.subplots(n_samples, 4, figsize=(12, 3 * n_samples))\n",
        "    if n_samples == 1:\n",
        "        axes = axes.reshape(1, -1)\n",
        "\n",
        "    fig.suptitle(f'{folder_path}_Image preprocessing steps', fontsize=16, fontweight='bold')\n",
        "\n",
        "    for idx, filename in enumerate(files):\n",
        "        img_path = os.path.join(folder_path, filename)\n",
        "        gray = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        if gray is None:\n",
        "            continue\n",
        "\n",
        "        # 1. 原始圖片\n",
        "        axes[idx, 0].imshow(gray, cmap='gray')\n",
        "        axes[idx, 0].set_title('1. original img')\n",
        "        axes[idx, 0].axis('off')\n",
        "\n",
        "        # 2. 自動反轉\n",
        "        if np.mean(gray) < 128:\n",
        "            inv = 255 - gray\n",
        "        else:\n",
        "            inv = gray.copy()\n",
        "\n",
        "        axes[idx, 1].imshow(inv, cmap='gray')\n",
        "        axes[idx, 1].set_title('2. auto invert\\n(white bg, dark digit)')\n",
        "        axes[idx, 1].axis('off')\n",
        "\n",
        "        # 3. 整張縮放到 img_size，並在灰階上加粗筆劃\n",
        "        digit_small = cv2.resize(\n",
        "            inv, img_size,\n",
        "            interpolation=cv2.INTER_AREA\n",
        "        )\n",
        "\n",
        "        # 反轉 + 膨脹 + 再反轉（加粗深色筆劃）\n",
        "        inv_small = 255 - digit_small\n",
        "        kernel = np.ones((2, 2), np.uint8)\n",
        "        inv_thick = cv2.dilate(inv_small, kernel, iterations=1)\n",
        "        digit_thick_gray = 255 - inv_thick\n",
        "\n",
        "        # 對比拉伸\n",
        "        digit_thick_gray = cv2.normalize(\n",
        "            digit_thick_gray, None, alpha=0, beta=255,\n",
        "            norm_type=cv2.NORM_MINMAX\n",
        "        )\n",
        "\n",
        "        # 這裡就已經是模型要吃的 16x16 灰階\n",
        "        axes[idx, 2].imshow(digit_thick_gray, cmap='gray')\n",
        "        axes[idx, 2].set_title(f'3. resize + gray-dilate\\n({img_size[0]}x{img_size[1]})')\n",
        "        axes[idx, 2].axis('off')\n",
        "\n",
        "        # 4. 放大顯示\n",
        "        disp = cv2.resize(\n",
        "            digit_thick_gray, (64, 64),\n",
        "            interpolation=cv2.INTER_NEAREST\n",
        "        )\n",
        "        axes[idx, 3].imshow(disp, cmap='gray')\n",
        "        axes[idx, 3].set_title('4. zoom out\\n(real img_size)')\n",
        "        axes[idx, 3].axis('off')\n",
        "\n",
        "\n",
        "\n",
        "    plt.tight_layout(rect=[0.0, 0, 1, 0.99])\n",
        "    plt.show()\n",
        "\n",
        "visualize_preprocessing('handwrite/dr',   n_samples=10, img_size=(16, 16))\n",
        "visualize_preprocessing('handwrite/mine', n_samples=10, img_size=(16, 16))\n"
      ],
      "metadata": {
        "id": "K54gFRp5PM0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 使用增強版函數\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"使用增強版預處理重新預測\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# 1) 醫師的手寫\n",
        "X_dr_enhanced, dr_names = load_handwrite_enhanced('handwrite/dr')\n",
        "dr_preds_new, dr_dists_new, _ = classifier.predict_batch(X_dr_enhanced)\n",
        "\n",
        "print(\"\\n=== handwrite/dr 增強後預測結果 ===\")\n",
        "for name, pred, dist in zip(dr_names, dr_preds_new, dr_dists_new):\n",
        "    print(f\"檔名: {name:>6s} -> 預測數字: {pred} (最小距離: {dist:.4f})\")\n",
        "\n",
        "# 2) 我的手寫\n",
        "X_mine_enhanced, mine_names = load_handwrite_enhanced('handwrite/mine')\n",
        "mine_preds_new, mine_dists_new, _ = classifier.predict_batch(X_mine_enhanced)\n",
        "\n",
        "print(\"\\n=== handwrite/mine 增強後預測結果 ===\")\n",
        "for name, pred, dist in zip(mine_names, mine_preds_new, mine_dists_new):\n",
        "    print(f\"檔名: {name:>6s} -> 預測數字: {pred} (最小距離: {dist:.4f})\")\n"
      ],
      "metadata": {
        "id": "8yGchophSnNO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dr_correct = sum(\n",
        "    int(name.split('.')[0]) == int(pred)\n",
        "    for name, pred in zip(dr_names, dr_preds_new)\n",
        ")\n",
        "\n",
        "print(f\"dr 正確 {dr_correct} / {len(dr_names)}\")\n",
        "\n",
        "mine_correct = sum(\n",
        "    int(name.split('.')[0]) == int(pred)\n",
        "    for name, pred in zip(mine_names, mine_preds_new)\n",
        ")\n",
        "\n",
        "print(f\"mine 正確 {mine_correct} / {len(mine_names)}\")"
      ],
      "metadata": {
        "id": "H9B8ZlX-hz0a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "手寫字_有框ROI+字體加粗"
      ],
      "metadata": {
        "id": "UoSdkVvOQLYk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_handwrite_enhanced_ROI(folder_path, img_size=(16, 16)):\n",
        "\n",
        "    images = []\n",
        "    names = []\n",
        "\n",
        "    print(f\"\\n從 {folder_path} 載入並增強圖片...\")\n",
        "\n",
        "    for filename in sorted(os.listdir(folder_path)):\n",
        "        if not filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "            continue\n",
        "\n",
        "        img_path = os.path.join(folder_path, filename)\n",
        "\n",
        "        # 0. 讀取灰階\n",
        "        gray = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "        if gray is None:\n",
        "            continue\n",
        "\n",
        "        # 1. 自動判斷是否需要反轉\n",
        "        mean_val = np.mean(gray)\n",
        "        if mean_val < 128:              # 平均偏暗，視為黑底白字\n",
        "            gray = 255 - gray           # 反轉成白底黑字（淺背景、深字）\n",
        "\n",
        "        # 2. 用二值化「找位置」(深色數字 → mask 的白色前景)\n",
        "        _, mask = cv2.threshold(\n",
        "            gray, 0, 255,\n",
        "            cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU\n",
        "        )\n",
        "\n",
        "        # 如果整張都沒有前景，就跳過\n",
        "        if np.count_nonzero(mask) == 0:\n",
        "            continue\n",
        "\n",
        "        # 3. 根據 mask 找 bounding box，裁出數字那一塊（用灰階圖）\n",
        "        ys, xs = np.where(mask > 0)\n",
        "        x_min, x_max = xs.min(), xs.max()\n",
        "        y_min, y_max = ys.min(), ys.max()\n",
        "        digit_roi = gray[y_min:y_max+1, x_min:x_max+1]\n",
        "\n",
        "        # 4. 先把 ROI 縮放到指定大小 (16x16)\n",
        "        digit_small = cv2.resize(\n",
        "            digit_roi, img_size,\n",
        "            interpolation=cv2.INTER_AREA\n",
        "        )\n",
        "\n",
        "        # 5. 在 16x16 灰階圖上做「反轉 + 膨脹 + 再反轉」來加粗深色筆劃\n",
        "        #    因為深色數字 → 反轉後變亮，對亮的部分做膨脹，再反轉回來\n",
        "        inv_small = 255 - digit_small          # 深色數字 → 變亮\n",
        "        kernel = np.ones((2, 2), np.uint8)\n",
        "        inv_thick = cv2.dilate(inv_small, kernel, iterations=1)\n",
        "        digit_thick_gray = 255 - inv_thick     # 反轉回深色數字\n",
        "\n",
        "        # 6. 可以順便做一點對比拉伸\n",
        "        digit_thick_gray = cv2.normalize(\n",
        "            digit_thick_gray, None, alpha=0, beta=255,\n",
        "            norm_type=cv2.NORM_MINMAX\n",
        "        )\n",
        "\n",
        "        # 7. 正規化到 [0, 1]\n",
        "        img_normalized = digit_thick_gray.astype(np.float32) / 255.0\n",
        "\n",
        "        images.append(img_normalized.flatten())\n",
        "        names.append(filename)\n",
        "\n",
        "        print(f\"  ✓ 處理: {filename}\")\n",
        "\n",
        "    images = np.array(images)\n",
        "    print(f\"共載入 {len(images)} 張圖片\\n\")\n",
        "    return images, names"
      ],
      "metadata": {
        "id": "-ja2_UlF6CkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_preprocessing(folder_path, n_samples=10, img_size=(16, 16)):\n",
        "\n",
        "    files = sorted([\n",
        "        f for f in os.listdir(folder_path)\n",
        "        if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
        "    ])[:n_samples]\n",
        "\n",
        "    fig, axes = plt.subplots(n_samples, 6, figsize=(18, 3 * n_samples))\n",
        "    if n_samples == 1:\n",
        "        axes = axes.reshape(1, -1)\n",
        "\n",
        "    fig.suptitle(f'{folder_path}_Image preprocessing steps', fontsize=16, fontweight='bold')\n",
        "\n",
        "    for idx, filename in enumerate(files):\n",
        "        img_path = os.path.join(folder_path, filename)\n",
        "        gray = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        if gray is None:\n",
        "            continue\n",
        "\n",
        "        # 1. 原始圖片\n",
        "        axes[idx, 0].imshow(gray, cmap='gray')\n",
        "        axes[idx, 0].set_title('1. original img')\n",
        "        axes[idx, 0].axis('off')\n",
        "\n",
        "        # 2. 自動反轉 → 確保白底黑字\n",
        "        if np.mean(gray) < 128:\n",
        "            inv = 255 - gray\n",
        "        else:\n",
        "            inv = gray.copy()\n",
        "        axes[idx, 1].imshow(inv, cmap='gray')\n",
        "        axes[idx, 1].set_title('2.inverse to w bg and black digits')\n",
        "        axes[idx, 1].axis('off')\n",
        "\n",
        "        # # 3. 二值化 mask\n",
        "        _, mask = cv2.threshold(\n",
        "            inv, 0, 255,\n",
        "            cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU\n",
        "        )\n",
        "        axes[idx, 2].imshow(mask, cmap='gray')\n",
        "        axes[idx, 2].set_title('3. binary mask')\n",
        "        axes[idx, 2].axis('off')\n",
        "\n",
        "        # 如果整張都沒有前景，就跳過\n",
        "        if np.count_nonzero(mask) == 0:\n",
        "            continue\n",
        "\n",
        "        # # 4. 根據 mask 裁出 ROI（灰階）\n",
        "        ys, xs = np.where(mask > 0)\n",
        "        x_min, x_max = xs.min(), xs.max()\n",
        "        y_min, y_max = ys.min(), ys.max()\n",
        "        roi = inv[y_min:y_max+1, x_min:x_max+1]\n",
        "        axes[idx, 3].imshow(roi, cmap='gray')\n",
        "        axes[idx, 3].set_title('4. Cut out ROI')\n",
        "        axes[idx, 3].axis('off')\n",
        "\n",
        "        # 5. ROI → resize → 在灰階上反轉 + 膨脹 + 再反轉\n",
        "        digit_small = cv2.resize(\n",
        "            roi, img_size,\n",
        "            interpolation=cv2.INTER_AREA\n",
        "        )\n",
        "\n",
        "        inv_small = 255 - digit_small\n",
        "        kernel = np.ones((2, 2), np.uint8)\n",
        "        inv_thick = cv2.dilate(inv_small, kernel, iterations=1)\n",
        "        digit_thick_gray = 255 - inv_thick\n",
        "\n",
        "        digit_thick_gray = cv2.normalize(\n",
        "            digit_thick_gray, None, alpha=0, beta=255,\n",
        "            norm_type=cv2.NORM_MINMAX\n",
        "        )\n",
        "\n",
        "        axes[idx, 4].imshow(digit_thick_gray, cmap='gray')\n",
        "        axes[idx, 4].set_title(f'5. resize + gray-dilate\\n({img_size[0]}x{img_size[1]})')\n",
        "        axes[idx, 4].axis('off')\n",
        "\n",
        "        # 6. 放大顯示\n",
        "        disp = cv2.resize(\n",
        "            digit_thick_gray, (64, 64),\n",
        "            interpolation=cv2.INTER_NEAREST\n",
        "        )\n",
        "        axes[idx, 5].imshow(disp, cmap='gray')\n",
        "        axes[idx, 5].set_title('6. zoom out\\n(real img_size)')\n",
        "        axes[idx, 5].axis('off')\n",
        "\n",
        "\n",
        "\n",
        "    plt.tight_layout(rect=[0.0, 0, 1, 0.99])\n",
        "    plt.show()\n",
        "visualize_preprocessing('handwrite/dr',   n_samples=10, img_size=(16, 16))\n",
        "visualize_preprocessing('handwrite/mine', n_samples=10, img_size=(16, 16))\n"
      ],
      "metadata": {
        "id": "VzdV1k9q6CgB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 使用增強版+ROI函數\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"使用增強版+ROI預處理重新預測\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# 1) 醫師的手寫\n",
        "X_dr_enhanced, dr_names = load_handwrite_enhanced_ROI('handwrite/dr')\n",
        "dr_preds_new, dr_dists_new, _ = classifier.predict_batch(X_dr_enhanced)\n",
        "\n",
        "print(\"\\n=== handwrite/dr 增強+ROI後預測結果 ===\")\n",
        "for name, pred, dist in zip(dr_names, dr_preds_new, dr_dists_new):\n",
        "    print(f\"檔名: {name:>6s} -> 預測數字: {pred} (最小距離: {dist:.4f})\")\n",
        "\n",
        "# 2) 我的手寫\n",
        "X_mine_enhanced, mine_names = load_handwrite_enhanced('handwrite/mine')\n",
        "mine_preds_new, mine_dists_new, _ = classifier.predict_batch(X_mine_enhanced)\n",
        "\n",
        "print(\"\\n=== handwrite/mine 增強+ROI後預測結果 ===\")\n",
        "for name, pred, dist in zip(mine_names, mine_preds_new, mine_dists_new):\n",
        "    print(f\"檔名: {name:>6s} -> 預測數字: {pred} (最小距離: {dist:.4f})\")\n"
      ],
      "metadata": {
        "id": "pLIQcnzE6Cb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dr_correct = sum(\n",
        "    int(name.split('.')[0]) == int(pred)\n",
        "    for name, pred in zip(dr_names, dr_preds_new)\n",
        ")\n",
        "\n",
        "print(f\"dr 正確 {dr_correct} / {len(dr_names)}\")\n",
        "\n",
        "mine_correct = sum(\n",
        "    int(name.split('.')[0]) == int(pred)\n",
        "    for name, pred in zip(mine_names, mine_preds_new)\n",
        ")\n",
        "\n",
        "print(f\"mine 正確 {mine_correct} / {len(mine_names)}\")"
      ],
      "metadata": {
        "id": "7JsH6J976CVL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 方法二 :SVD\n"
      ],
      "metadata": {
        "id": "HdePFcYiegXa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    accuracy_score,\n",
        "    classification_report,\n",
        "    mean_squared_error\n",
        ")"
      ],
      "metadata": {
        "id": "PQoTq7mklngx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# 1.先蒐集訓練的影像資料，彙整成第一步需要的tensor\n",
        "# ============================================================\n",
        "def load_usps_split(base_path, img_size=(16, 16)):\n",
        "\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    print(f\"正在載入資料從：{base_path}\")\n",
        "\n",
        "    for digit in range(10):\n",
        "        digit_path = os.path.join(base_path, str(digit))\n",
        "\n",
        "        if not os.path.exists(digit_path):\n",
        "            print(f\"  警告：找不到資料夾 {digit_path}\")\n",
        "            continue\n",
        "\n",
        "        img_files = os.listdir(digit_path)\n",
        "        print(f\"  數字 {digit}: 找到 {len(img_files)} 張圖片\")\n",
        "\n",
        "        for filename in img_files:\n",
        "            if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                img_path = os.path.join(digit_path, filename)\n",
        "                img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "                if img is not None:\n",
        "                    # 統一影像大小\n",
        "                    if img.shape != img_size:\n",
        "                        img = cv2.resize(img, img_size)\n",
        "\n",
        "                    # 正規化到 [0, 1]\n",
        "                    img = img.astype(np.float32) / 255.0\n",
        "\n",
        "                    images.append(img)\n",
        "                    labels.append(digit)\n",
        "\n",
        "    images = np.array(images)   # shape: (N, H, W)---->tensor\n",
        "    labels = np.array(labels)   # shape: (N,)\n",
        "    print(f\"載入完成：{base_path} -> images 形狀 {images.shape}\")\n",
        "    return images, labels\n",
        "\n",
        "load_usps_split(\"/content/usps_inverted/train\", img_size=(16, 16))"
      ],
      "metadata": {
        "id": "AAzLjqhylpKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# 2. 建立「每一個 digit 一個 SVD 子空間」\n",
        "#    對同一類別的所有訓練樣本一起做 SVD\n",
        "# ============================================================\n",
        "\n",
        "def build_svd_subspaces_per_digit(train_imgs, train_labels, k):\n",
        "\n",
        "    H, W = train_imgs.shape[1], train_imgs.shape[2]\n",
        "    D = H * W\n",
        "\n",
        "    subspaces = {}\n",
        "\n",
        "    print(f\"\\n開始為每個 digit 建立 SVD 子空間 (要求 k = {k}) ...\")\n",
        "\n",
        "    for digit in range(10):\n",
        "        # 取出該 digit 的所有訓練樣本\n",
        "        idx = np.where(train_labels == digit)[0]\n",
        "        if len(idx) == 0:\n",
        "            print(f\"  警告：digit {digit} 沒有訓練資料，略過\")\n",
        "            continue\n",
        "\n",
        "        Xc = train_imgs[idx].reshape(len(idx), D)  # (n_c, D)\n",
        "\n",
        "        # 類別平均 μ_c\n",
        "        mean_c = Xc.mean(axis=0)                   # (D,)\n",
        "\n",
        "        # 去平均\n",
        "        Xc_centered = Xc - mean_c                 # (n_c, D)\n",
        "\n",
        "        # 做 SVD：Xc_centered = U S V^T\n",
        "        # 這裡 feature space 的正交基底在 V (右奇異向量)\n",
        "        U, S, Vt = np.linalg.svd(Xc_centered, full_matrices=False)\n",
        "\n",
        "        # 實際可用的最大 k_c\n",
        "        k_c = min(k, Vt.shape[0])\n",
        "\n",
        "        # 取前 k_c 個右奇異向量的轉置當作 U_k（D x k_c）\n",
        "        Uk = Vt[:k_c, :].T                        # (D, k_c)\n",
        "\n",
        "        subspaces[digit] = {\n",
        "            'mean': mean_c,\n",
        "            'Uk':   Uk\n",
        "        }\n",
        "\n",
        "        print(f\"  digit {digit}: n = {len(idx)}, 實際使用 k_c = {k_c}\")\n",
        "\n",
        "    return subspaces"
      ],
      "metadata": {
        "id": "R2yaL5ETlq4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ============================================================\n",
        "# residual 計算函式\n",
        "# residual_c = || (I - Uk Uk^T) (x - μ_c) ||_2\n",
        "# ============================================================\n",
        "\n",
        "def residual_norm_svd(x, mean_c, Uk):\n",
        "\n",
        "    # 1. 去平均：z = x - μ_c\n",
        "    z = x - mean_c                    # (D,)\n",
        "\n",
        "    # 2. 投影到子空間：proj = Uk (Uk^T z)\n",
        "    coeff = Uk.T @ z                  # (k_c,)\n",
        "    proj  = Uk @ coeff               # (D,)\n",
        "\n",
        "    # 3. 殘差向量：(I - Uk Uk^T) z = z - proj\n",
        "    res_vec = z - proj                # (D,)\n",
        "\n",
        "    # 4. 取 2-norm\n",
        "    residual = np.linalg.norm(res_vec, ord=2)\n",
        "    return residual\n"
      ],
      "metadata": {
        "id": "ZFkujNPdO945"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# 3. 使用「每個 digit 的 SVD 子空間」做分類\n",
        "#    residual_c = || (I - U_k U_k^T) (x - μ_c) ||_2\n",
        "# ============================================================\n",
        "\n",
        "def classify_with_svd_subspaces_formula(subspaces, test_imgs):\n",
        "\n",
        "    N_test = test_imgs.shape[0]\n",
        "    H, W   = test_imgs.shape[1], test_imgs.shape[2]\n",
        "    D      = H * W\n",
        "\n",
        "    # flatten 每張圖 → (N_test, D)\n",
        "    X_test_flat = test_imgs.reshape(N_test, D)\n",
        "\n",
        "    y_pred = []\n",
        "    residuals_pred = []\n",
        "\n",
        "    digits = sorted(subspaces.keys())\n",
        "\n",
        "    print(\"\\n開始使用公式 ||(I - Uk Uk^T)(x - μ_c)||_2 對 testing 影像做分類 ...\")\n",
        "\n",
        "    for i, x in enumerate(X_test_flat):\n",
        "        best_digit    = None\n",
        "        best_residual = None\n",
        "\n",
        "        for digit in digits:\n",
        "            mean_c = subspaces[digit]['mean']   # (D,)\n",
        "            Uk     = subspaces[digit]['Uk']     # (D, k_c)\n",
        "\n",
        "            residual = residual_norm_svd(x, mean_c, Uk)\n",
        "\n",
        "            if (best_residual is None) or (residual < best_residual):\n",
        "                best_residual = residual\n",
        "                best_digit    = digit\n",
        "\n",
        "        y_pred.append(best_digit)\n",
        "        residuals_pred.append(best_residual)\n",
        "\n",
        "        if (i + 1) % 200 == 0 or (i + 1) == N_test:\n",
        "            print(f\"  已完成 {i+1}/{N_test} 張 test\")\n",
        "\n",
        "    return np.array(y_pred), np.array(residuals_pred)\n"
      ],
      "metadata": {
        "id": "JxI-Yi0oO92M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def visualize_svd_confusion_matrix(conf_matrix, accuracy, k=20):\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(conf_matrix,\n",
        "                annot=True,\n",
        "                fmt='d',\n",
        "                cmap='Blues',\n",
        "                xticklabels=range(10),\n",
        "                yticklabels=range(10))\n",
        "\n",
        "    plt.title(f'Confusion Matrix - SVD Subspace (k={k})\\nAccuracy: {accuracy:.2%}',\n",
        "              fontsize=14, weight='bold')\n",
        "    plt.xlabel('Predicted Label', fontsize=12)\n",
        "    plt.ylabel('True Label', fontsize=12)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'SVD_confusion_matrix_k{k}.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "w5rAx6QRVRhN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# 4. 主程式：多個 k 值，分別計算 accuracy 與 label RMSE\n",
        "# ============================================================\n",
        "\n",
        "def main():\n",
        "\n",
        "    TRAIN_PATH = 'usps_inverted/train'\n",
        "    TEST_PATH  = 'usps_inverted/test'\n",
        "    img_size = (16, 16)\n",
        "\n",
        "    # 想要測試的 k 清單\n",
        "    K_LIST = [2,10,15,20,30,40,50,255]\n",
        "\n",
        "    # =================================\n",
        "\n",
        "    # Step 1: 載入一次 train / test 資料\n",
        "    X_train_imgs, y_train = load_usps_split(TRAIN_PATH, img_size=img_size)\n",
        "    X_test_imgs,  y_test  = load_usps_split(TEST_PATH,  img_size=img_size)\n",
        "\n",
        "    for k in K_LIST:\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(f\"現在使用 k = {k} 的子空間做分類\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        # Step 2: 建立每個 digit 的 SVD 子空間\n",
        "        subspaces = build_svd_subspaces_per_digit(X_train_imgs, y_train, k)\n",
        "\n",
        "        # Step 3: 用公式做分類\n",
        "        y_pred, residuals_pred = classify_with_svd_subspaces_formula(subspaces, X_test_imgs)\n",
        "\n",
        "        # Step 4: 評估\n",
        "        acc = accuracy_score(y_test, y_pred)\n",
        "        mse_labels = mean_squared_error(y_test, y_pred)\n",
        "        rmse_labels = np.sqrt(mse_labels)\n",
        "\n",
        "        print(f\"\\n=== k = {k} 的結果 ===\")\n",
        "        print(\"Accuracy :\", acc)\n",
        "        print(\"Label RMSE (均方根誤差):\", rmse_labels)\n",
        "\n",
        "        print(\"\\n分類報告：\")\n",
        "        print(classification_report(y_test, y_pred))\n",
        "\n",
        "        cm = confusion_matrix(y_test, y_pred)\n",
        "        print(\"Confusion Matrix：\")\n",
        "        print(cm)\n",
        "\n",
        "        if k == 30:\n",
        "            visualize_svd_confusion_matrix(cm, acc, k)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "A2zslkyeO9zt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##\n",
        "K = 30\n",
        "TRAIN_PATH = 'usps_inverted/train'\n",
        "TEST_PATH  = 'usps_inverted/test'\n",
        "img_size = (16, 16)\n",
        "X_train_imgs, y_train = load_usps_split(TRAIN_PATH, img_size=img_size)\n",
        "X_test_imgs,  y_test  = load_usps_split(TEST_PATH,  img_size=img_size)"
      ],
      "metadata": {
        "id": "_NK41mTTRX-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# 4. 視覺化：某個 digit 的 residual 分佈 residual_c\n",
        "# ============================================================\n",
        "\n",
        "def visualize_residual_confusion(digit, test_imgs, y_test, subspaces):\n",
        "\n",
        "    N_test = test_imgs.shape[0]\n",
        "    H, W   = test_imgs.shape[1], test_imgs.shape[2]\n",
        "    D      = H * W\n",
        "\n",
        "    # flatten 測試影像\n",
        "    X_test_flat = test_imgs.reshape(N_test, D)\n",
        "\n",
        "    # 找出所有真實標籤是 digit 的樣本 index\n",
        "    digit_indices = np.where(y_test == digit)[0]\n",
        "    print(f\"\\n分析數字 {digit} 的 residual 分佈 (共 {len(digit_indices)} 個樣本)\")\n",
        "\n",
        "    digits = sorted(subspaces.keys())\n",
        "\n",
        "    # 收集每一個樣本的 residual 曲線\n",
        "    all_residuals = []\n",
        "\n",
        "    for idx in digit_indices:\n",
        "        x = X_test_flat[idx]\n",
        "        residuals_to_all = []\n",
        "\n",
        "        for d in digits:\n",
        "            mean_c = subspaces[d]['mean']   # (D,)\n",
        "            Uk     = subspaces[d]['Uk']     # (D, k_c)\n",
        "            r = residual_norm_svd(x, mean_c, Uk)\n",
        "            residuals_to_all.append(r)\n",
        "\n",
        "        all_residuals.append(residuals_to_all)\n",
        "\n",
        "    all_residuals = np.array(all_residuals)   # (N_samples_digit, 10)\n",
        "\n",
        "    # --- 畫圖 ---\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # 每個樣本一條藍線\n",
        "    for r in all_residuals:\n",
        "        plt.plot(digits, r, alpha=0.2, color='blue')\n",
        "\n",
        "    # 平均 residual（紅線）\n",
        "    avg_residuals = all_residuals.mean(axis=0)\n",
        "    plt.plot(digits, avg_residuals, 'r-', linewidth=3, label='mean residual')\n",
        "\n",
        "    plt.xlabel('Digit subspace k', fontsize=12)\n",
        "    plt.ylabel(r'Residual norm $\\|(I - U_k U_k^T)(x - \\mu_k)\\|_2$', fontsize=12)\n",
        "    plt.title(f'No. {digit} residual to every digit subspace', fontsize=14, fontweight='bold')\n",
        "    plt.xticks(digits)\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # --- 找最容易混淆 / 最不像的類別（依平均 residual）---\n",
        "    avg_for_arg = avg_residuals.copy()\n",
        "\n",
        "    # 把自己那類先設成 inf，只考慮其他類\n",
        "    self_idx = digits.index(digit)\n",
        "    avg_for_arg[self_idx] = np.inf\n",
        "\n",
        "    confused_with = digits[np.argmin(avg_for_arg)]\n",
        "    worst_with    = digits[np.argmax(avg_for_arg)]\n",
        "\n",
        "    print(f\"數字 {digit} 最容易被混淆為: {confused_with} (平均 residual = {avg_residuals[confused_with]:.4f})\")\n",
        "    print(f\"數字 {digit} 最不像的是: {worst_with} (平均 residual = {avg_residuals[worst_with]:.4f})\")\n"
      ],
      "metadata": {
        "id": "uKdQKJ2KO9w5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============  k = 30 時 residual 與數字的關係 ============\n",
        "\n",
        "# 1. 建立 K=30 的 SVD 子空間\n",
        "K = 30\n",
        "subspaces_k30 = build_svd_subspaces_per_digit(X_train_imgs, y_train, k=K)\n",
        "\n",
        "# 2.（選擇性）用 K=30 做分類\n",
        "y_pred_svd_30, residuals_pred_30 = classify_with_svd_subspaces_formula(\n",
        "    subspaces_k30, X_test_imgs\n",
        ")\n",
        "\n",
        "# 3. 視覺化某些數字的 residual 分佈（K=30 的結果）\n",
        "visualize_residual_confusion(0, X_test_imgs, y_test, subspaces_k30)\n",
        "visualize_residual_confusion(1, X_test_imgs, y_test, subspaces_k30)\n",
        "visualize_residual_confusion(5, X_test_imgs, y_test, subspaces_k30)\n",
        "visualize_residual_confusion(7, X_test_imgs, y_test, subspaces_k30)\n"
      ],
      "metadata": {
        "id": "tca2KXMzQzgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================= 視覺化前置 =================\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "\n",
        "TRAIN_PATH = 'usps_inverted/train'\n",
        "TEST_PATH  = 'usps_inverted/test'\n",
        "img_size   = (16, 16)\n",
        "H, W       = img_size\n",
        "\n",
        "# 重新載入一次資料\n",
        "X_train_imgs, y_train = load_usps_split(TRAIN_PATH, img_size=img_size)\n",
        "X_test_imgs,  y_test  = load_usps_split(TEST_PATH,  img_size=img_size)\n"
      ],
      "metadata": {
        "id": "rlBmm24noWwX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============ 1. 0–9 在 k = 30 subspace 的樣子 ============\n",
        "\n",
        "k_vis = 30\n",
        "subspaces_30 = build_svd_subspaces_per_digit(X_train_imgs, y_train, k_vis)\n",
        "\n",
        "for digit in range(10):\n",
        "    if digit not in subspaces_30:\n",
        "        print(f\"digit {digit} 沒有 subspace，被略過\")\n",
        "        continue\n",
        "\n",
        "    info = subspaces_30[digit]\n",
        "    mean_img = info['mean'].reshape(H, W)\n",
        "    Uk       = info['Uk']          # (D, k_c)\n",
        "    k_c      = Uk.shape[1]\n",
        "\n",
        "    # 要顯示幾個 basis（最多不超過 k_c）\n",
        "    n_show = min(5, k_c)\n",
        "\n",
        "    fig, axes = plt.subplots(1, n_show + 1,\n",
        "                             figsize=(2.5 * (n_show + 1), 2.5))\n",
        "\n",
        "    # 第 1 張：平均影像\n",
        "    axes[0].imshow(mean_img, cmap='gray')\n",
        "    axes[0].set_title(f'{digit} mean')\n",
        "    axes[0].axis('off')\n",
        "\n",
        "    # 後面：前幾個 basis\n",
        "    for i in range(n_show):\n",
        "        basis_img = Uk[:, i].reshape(H, W)\n",
        "        axes[i + 1].imshow(basis_img, cmap='gray')\n",
        "        axes[i + 1].set_title(f'basis {i+1}')\n",
        "        axes[i + 1].axis('off')\n",
        "\n",
        "    plt.suptitle(f'Digit {digit} subspace (k={k_vis})')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "3G8Y0kHdtlwi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============ 2. 不同 k 時，預測錯誤的前5 個樣本 ============\n",
        "\n",
        "K_LIST = [20,30,40]\n",
        "results = {}\n",
        "\n",
        "# 先把每個 k 的分類結果算好\n",
        "for k in K_LIST:\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(f\"Use k = {k}'s subspace (for visualization)\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    subspaces_k = build_svd_subspaces_per_digit(X_train_imgs, y_train, k)\n",
        "    y_pred_k, residuals_k = classify_with_svd_subspaces_formula(subspaces_k, X_test_imgs)\n",
        "\n",
        "    results[k] = {\n",
        "        'subspaces': subspaces_k,\n",
        "        'y_pred': y_pred_k,\n",
        "        'residuals': residuals_k,\n",
        "    }\n",
        "\n",
        "# 對每個 k，畫出「預測錯誤的前 5 張」\n",
        "for k in K_LIST:\n",
        "    y_pred = results[k]['y_pred']\n",
        "    mis_idx = np.where(y_pred != y_test)[0]   # 所有錯誤 index\n",
        "\n",
        "    if len(mis_idx) == 0:\n",
        "        print(f\"k = {k}: all are correct \")\n",
        "        continue\n",
        "\n",
        "    top_idx = mis_idx[:5]                    # 取前 5 個\n",
        "    n = len(top_idx)\n",
        "\n",
        "    cols = 5\n",
        "    rows = math.ceil(n / cols)\n",
        "\n",
        "    fig, axes = plt.subplots(rows, cols, figsize=(3 * cols, 3 * rows))\n",
        "    axes = np.array(axes).reshape(-1)\n",
        "\n",
        "    for ax_i, idx in enumerate(top_idx):\n",
        "        axes[ax_i].imshow(X_test_imgs[idx], cmap='gray')\n",
        "        axes[ax_i].set_title(f\"true {y_test[idx]} → pred {y_pred[idx]}\")\n",
        "        axes[ax_i].axis('off')\n",
        "\n",
        "    for j in range(n, rows * cols):\n",
        "        axes[j].axis('off')\n",
        "\n",
        "    plt.suptitle( f\"k = {k},The first {n} test samples that were predicted wrong \")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "RcwfuXf8toZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 方法二:SVD_自己手寫預測"
      ],
      "metadata": {
        "id": "MKjznfqpxW6l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_PATH = 'usps_inverted/train'\n",
        "img_size   = (16, 16)\n",
        "k_best     = 30   # 實驗出來最好的 k\n",
        "\n",
        "# 1. 載入訓練資料\n",
        "X_train_imgs, y_train = load_usps_split(TRAIN_PATH, img_size=img_size)\n",
        "\n",
        "# 2. 建立 SVD 子空間（k = 30）\n",
        "subspaces_best = build_svd_subspaces_per_digit(X_train_imgs, y_train, k_best)\n"
      ],
      "metadata": {
        "id": "_Da4TSkrf6Em"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.手寫字_原始版(無框ROI+無字體加粗)\n"
      ],
      "metadata": {
        "id": "IPB24ZZXfIeh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def svd_predict_handwrite_folder(folder_path, subspaces, img_size=(16, 16)):\n",
        "\n",
        "    X_flat, names = load_handwrite_original(folder_path, img_size=img_size)  # (N, 256)\n",
        "\n",
        "    # 轉回 (N, H, W) 給 SVD 分類器使用\n",
        "    H, W = img_size\n",
        "    X_imgs = X_flat.reshape(-1, H, W)   # (N, H, W)\n",
        "\n",
        "    # 用 SVD 子空間公式做分類\n",
        "    y_pred, residuals = classify_with_svd_subspaces_formula(subspaces, X_imgs)\n",
        "\n",
        "    return names, y_pred, residuals\n"
      ],
      "metadata": {
        "id": "ubOQs9e1gBNk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"使用 SVD 子空間分類器，對手寫資料重新預測\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# 1) 醫師的手寫（handwrite/dr）\n",
        "dr_names, dr_preds_new, dr_residuals_new = svd_predict_handwrite_folder(\n",
        "    'handwrite/dr',\n",
        "    subspaces_best,          # 前面建好的 k=30 子空間\n",
        "    img_size=(16, 16)\n",
        ")\n",
        "\n",
        "print(\"\\n=== handwrite/dr 預測結果 (SVD) ===\")\n",
        "for name, pred, res in zip(dr_names, dr_preds_new, dr_residuals_new):\n",
        "    print(f\"檔名: {name:>6s} -> 預測數字: {pred} (最小 residual: {res:.4f})\")\n",
        "\n",
        "# 2) 我的手寫（handwrite/mine）\n",
        "mine_names, mine_preds_new, mine_residuals_new = svd_predict_handwrite_folder(\n",
        "    'handwrite/mine',\n",
        "    subspaces_best,\n",
        "    img_size=(16, 16)\n",
        ")\n",
        "\n",
        "print(\"\\n=== handwrite/mine 預測結果 (SVD) ===\")\n",
        "for name, pred, res in zip(mine_names, mine_preds_new, mine_residuals_new):\n",
        "    print(f\"檔名: {name:>6s} -> 預測數字: {pred} (最小 residual: {res:.4f})\")\n"
      ],
      "metadata": {
        "id": "NWJ90OhdfRYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dr_correct = sum(\n",
        "    int(name.split('.')[0]) == int(pred)\n",
        "    for name, pred in zip(dr_names, dr_preds_new)\n",
        ")\n",
        "print(f\"dr 正確 {dr_correct} / {len(dr_names)}\")\n",
        "\n",
        "mine_correct = sum(\n",
        "    int(name.split('.')[0]) == int(pred)\n",
        "    for name, pred in zip(mine_names, mine_preds_new)\n",
        ")\n",
        "print(f\"mine 正確 {mine_correct} / {len(mine_names)}\")\n"
      ],
      "metadata": {
        "id": "fQ1QQcOSfRVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def visualize_preprocessing_svd(folder_path, subspaces, n_samples=10, img_size=(16, 16)):\n",
        "\n",
        "    # 取得 k\n",
        "    some_digit = sorted(subspaces.keys())[0]\n",
        "    k_vis = subspaces[some_digit]['Uk'].shape[1]\n",
        "\n",
        "    files = sorted([\n",
        "        f for f in os.listdir(folder_path)\n",
        "        if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
        "    ])[:n_samples]\n",
        "\n",
        "    fig, axes = plt.subplots(n_samples, 4, figsize=(12, 3 * n_samples))\n",
        "    if n_samples == 1:\n",
        "        axes = axes.reshape(1, -1)\n",
        "\n",
        "    fig.suptitle(\n",
        "        f'{folder_path} - SVD preprocessing & prediction (k={k_vis})',\n",
        "        fontsize=18,\n",
        "        fontweight='bold'\n",
        "    )\n",
        "\n",
        "    H, W = img_size\n",
        "    digits = sorted(subspaces.keys())\n",
        "\n",
        "    for idx, filename in enumerate(files):\n",
        "        img_path = os.path.join(folder_path, filename)\n",
        "        gray = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "        if gray is None:\n",
        "            continue\n",
        "\n",
        "        # 1. 原始圖片\n",
        "        axes[idx, 0].imshow(gray, cmap='gray')\n",
        "        axes[idx, 0].set_title('1. original img')\n",
        "        axes[idx, 0].axis('off')\n",
        "\n",
        "        # 2. 自動反轉\n",
        "        if np.mean(gray) < 128:\n",
        "            inv = 255 - gray   # 原本偏暗，視為黑底白字 → 反轉\n",
        "        else:\n",
        "            inv = gray.copy()  # 原本就白底黑字，不動\n",
        "\n",
        "        axes[idx, 1].imshow(inv, cmap='gray')\n",
        "        axes[idx, 1].set_title('2. auto invert\\n(white bg, dark digit)')\n",
        "        axes[idx, 1].axis('off')\n",
        "\n",
        "        # 3. 縮放到 img_size，並正規化到 [0,1]\n",
        "        digit_small = cv2.resize(\n",
        "            inv, img_size,\n",
        "            interpolation=cv2.INTER_AREA\n",
        "        )\n",
        "        img_norm = digit_small.astype(np.float32) / 255.0\n",
        "        x = img_norm.flatten()  # (D,)\n",
        "\n",
        "        axes[idx, 2].imshow(img_norm, cmap='gray')\n",
        "        axes[idx, 2].set_title(f'3. resize + normalize\\n({img_size[0]}x{img_size[1]})')\n",
        "        axes[idx, 2].axis('off')\n",
        "\n",
        "        # 4. 用 SVD 子空間做預測 + 重建\n",
        "        best_digit = None\n",
        "        best_res   = None\n",
        "        best_recon = None\n",
        "\n",
        "        for d in digits:\n",
        "            mean_c = subspaces[d]['mean']   # (D,)\n",
        "            Uk     = subspaces[d]['Uk']     # (D, k)\n",
        "\n",
        "            # residual 計算\n",
        "            z = x - mean_c\n",
        "            coeff = Uk.T @ z\n",
        "            proj  = Uk @ coeff\n",
        "            res_vec = z - proj\n",
        "            residual = np.linalg.norm(res_vec, ord=2)\n",
        "\n",
        "            if (best_res is None) or (residual < best_res):\n",
        "                best_res   = residual\n",
        "                best_digit = d\n",
        "                best_recon = mean_c + proj   # 重建影像 (D,)\n",
        "\n",
        "        if best_recon is not None:\n",
        "            recon_img = best_recon.reshape(H, W)\n",
        "            axes[idx, 3].imshow(recon_img, cmap='gray')\n",
        "            axes[idx, 3].set_title(\n",
        "                f'4. SVD recon\\npred:{best_digit}, r={best_res:.3f}'\n",
        "            )\n",
        "            axes[idx, 3].axis('off')\n",
        "\n",
        "    plt.tight_layout(rect=[0.0, 0, 1, 0.99])\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "VWG7lFJYfRS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 用 k=30 建好的 SVD 子空間\n",
        "subspaces_best = build_svd_subspaces_per_digit(X_train_imgs, y_train, k=30)\n",
        "\n",
        "visualize_preprocessing_svd('handwrite/dr',   subspaces_best, n_samples=10, img_size=(16, 16))\n",
        "visualize_preprocessing_svd('handwrite/mine', subspaces_best, n_samples=10, img_size=(16, 16))\n"
      ],
      "metadata": {
        "id": "hXeywv9XfRQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.手寫字_無框ROI+字體加粗"
      ],
      "metadata": {
        "id": "T0fQrfd6fIaG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def svd_predict_handwrite_folder_2(folder_path, subspaces, img_size=(16, 16)):\n",
        "\n",
        "    # 使用字變粗的前處理\n",
        "    X_flat, names = load_handwrite_enhanced(folder_path, img_size=img_size)  # (N, 256)\n",
        "\n",
        "    # 轉回 (N, H, W) 給 SVD 分類器使用\n",
        "    H, W = img_size\n",
        "    X_imgs = X_flat.reshape(-1, H, W)   # (N, H, W)\n",
        "\n",
        "    # 用 SVD 子空間公式做分類\n",
        "    y_pred, residuals = classify_with_svd_subspaces_formula(subspaces, X_imgs)\n",
        "\n",
        "    return names, y_pred, residuals\n"
      ],
      "metadata": {
        "id": "oxQ1oXU5goJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"使用 SVD 子空間分類器，對字邊粗的手寫資料重新預測\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# 1) 醫師的手寫（handwrite/dr）\n",
        "dr_names, dr_preds_new, dr_residuals_new = svd_predict_handwrite_folder_2(\n",
        "    'handwrite/dr',\n",
        "    subspaces_best,          # 前面建好的 k=30 子空間\n",
        "    img_size=(16, 16)\n",
        ")\n",
        "\n",
        "print(\"\\n=== handwrite/dr 預測結果 (SVD) ===\")\n",
        "for name, pred, res in zip(dr_names, dr_preds_new, dr_residuals_new):\n",
        "    print(f\"檔名: {name:>6s} -> 預測數字: {pred} (最小 residual: {res:.4f})\")\n",
        "\n",
        "# 2) 我的手寫（handwrite/mine）\n",
        "mine_names, mine_preds_new, mine_residuals_new = svd_predict_handwrite_folder_2(\n",
        "    'handwrite/mine',\n",
        "    subspaces_best,\n",
        "    img_size=(16, 16)\n",
        ")\n",
        "\n",
        "print(\"\\n=== handwrite/mine 預測結果 (SVD) ===\")\n",
        "for name, pred, res in zip(mine_names, mine_preds_new, mine_residuals_new):\n",
        "    print(f\"檔名: {name:>6s} -> 預測數字: {pred} (最小 residual: {res:.4f})\")\n"
      ],
      "metadata": {
        "id": "jL1qSze1goJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dr_correct = sum(\n",
        "    int(name.split('.')[0]) == int(pred)\n",
        "    for name, pred in zip(dr_names, dr_preds_new)\n",
        ")\n",
        "print(f\"dr 正確 {dr_correct} / {len(dr_names)}\")\n",
        "\n",
        "mine_correct = sum(\n",
        "    int(name.split('.')[0]) == int(pred)\n",
        "    for name, pred in zip(mine_names, mine_preds_new)\n",
        ")\n",
        "print(f\"mine 正確 {mine_correct} / {len(mine_names)}\")\n"
      ],
      "metadata": {
        "id": "OJb0gu3MgoJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def visualize_preprocessing__2_svd(folder_path, subspaces, n_samples=10, img_size=(16, 16)):\n",
        "\n",
        "    files = sorted([\n",
        "        f for f in os.listdir(folder_path)\n",
        "        if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
        "    ])[:n_samples]\n",
        "\n",
        "    fig, axes = plt.subplots(n_samples, 4, figsize=(12, 3 * n_samples))\n",
        "    if n_samples == 1:\n",
        "        axes = axes.reshape(1, -1)\n",
        "\n",
        "    # 取一個 digit 看看 k 值\n",
        "    some_digit = sorted(subspaces.keys())[0]\n",
        "    k_vis = subspaces[some_digit]['Uk'].shape[1]\n",
        "\n",
        "    fig.suptitle(\n",
        "        f'{folder_path}_Image preprocessing (dilate) + SVD (k={k_vis})',\n",
        "        fontsize=16, fontweight='bold'\n",
        "    )\n",
        "\n",
        "    H, W = img_size\n",
        "    digits = sorted(subspaces.keys())\n",
        "\n",
        "    for idx, filename in enumerate(files):\n",
        "        img_path = os.path.join(folder_path, filename)\n",
        "        gray = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        if gray is None:\n",
        "            continue\n",
        "\n",
        "        # 1. 原始圖片\n",
        "        axes[idx, 0].imshow(gray, cmap='gray')\n",
        "        axes[idx, 0].set_title('1. original img')\n",
        "        axes[idx, 0].axis('off')\n",
        "\n",
        "        # 2. 自動反轉\n",
        "        if np.mean(gray) < 128:\n",
        "            inv = 255 - gray   # 原本偏暗，視為黑底白字 → 反轉\n",
        "        else:\n",
        "            inv = gray.copy()  # 原本就白底黑字，不動\n",
        "\n",
        "        axes[idx, 1].imshow(inv, cmap='gray')\n",
        "        axes[idx, 1].set_title('2. auto invert\\n(white bg, dark digit)')\n",
        "        axes[idx, 1].axis('off')\n",
        "\n",
        "        # 3. 縮放 + 加粗筆劃\n",
        "        digit_small = cv2.resize(\n",
        "            inv, img_size,\n",
        "            interpolation=cv2.INTER_AREA\n",
        "        )\n",
        "\n",
        "        # 反轉 + 膨脹 + 再反轉（加粗深色筆劃）\n",
        "        inv_small = 255 - digit_small\n",
        "        kernel = np.ones((2, 2), np.uint8)\n",
        "        inv_thick = cv2.dilate(inv_small, kernel, iterations=1)\n",
        "        digit_thick_gray = 255 - inv_thick\n",
        "\n",
        "        # 對比拉伸\n",
        "        digit_thick_gray = cv2.normalize(\n",
        "            digit_thick_gray, None, alpha=0, beta=255,\n",
        "            norm_type=cv2.NORM_MINMAX\n",
        "        )\n",
        "\n",
        "        axes[idx, 2].imshow(digit_thick_gray, cmap='gray')\n",
        "        axes[idx, 2].set_title(f'3. resize + gray-dilate\\n({img_size[0]}x{img_size[1]})')\n",
        "        axes[idx, 2].axis('off')\n",
        "\n",
        "        # 丟進 SVD 分類器的輸入：先正規化到 [0,1] 再 flatten\n",
        "        img_norm = digit_thick_gray.astype(np.float32) / 255.0\n",
        "        x = img_norm.flatten()  # (D,)\n",
        "\n",
        "        # 4. 用 SVD 子空間做預測 + 重建\n",
        "        best_digit = None\n",
        "        best_res   = None\n",
        "        best_recon = None\n",
        "\n",
        "        for d in digits:\n",
        "            mean_c = subspaces[d]['mean']   # (D,)\n",
        "            Uk     = subspaces[d]['Uk']     # (D, k)\n",
        "\n",
        "            z = x - mean_c\n",
        "            coeff = Uk.T @ z\n",
        "            proj  = Uk @ coeff\n",
        "            res_vec = z - proj\n",
        "            residual = np.linalg.norm(res_vec, ord=2)\n",
        "\n",
        "            if (best_res is None) or (residual < best_res):\n",
        "                best_res   = residual\n",
        "                best_digit = d\n",
        "                best_recon = mean_c + proj   # (D,)\n",
        "\n",
        "        if best_recon is not None:\n",
        "            recon_img = best_recon.reshape(H, W)\n",
        "            axes[idx, 3].imshow(recon_img, cmap='gray')\n",
        "            axes[idx, 3].set_title(\n",
        "                f'4. SVD recon\\npred:{best_digit}, r={best_res:.3f}'\n",
        "            )\n",
        "            axes[idx, 3].axis('off')\n",
        "\n",
        "    plt.tight_layout(rect=[0.0, 0, 1, 0.99])\n",
        "    plt.show()\n",
        "\n",
        "visualize_preprocessing__2_svd('handwrite/dr',   subspaces_best, n_samples=10, img_size=(16, 16))\n",
        "visualize_preprocessing__2_svd('handwrite/mine', subspaces_best, n_samples=10, img_size=(16, 16))\n"
      ],
      "metadata": {
        "id": "uNGYDIKlfS3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.手寫字_ROI+字體加粗"
      ],
      "metadata": {
        "id": "63y_4DP2fIV3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def svd_predict_handwrite_folder_3(folder_path, subspaces, img_size=(16, 16)):\n",
        "\n",
        "    # 使用字變粗+ROI的前處理\n",
        "    X_flat, names = load_handwrite_enhanced_ROI(folder_path, img_size=img_size)  # (N, 256)\n",
        "\n",
        "    # 轉回 (N, H, W) 給 SVD 分類器使用\n",
        "    H, W = img_size\n",
        "    X_imgs = X_flat.reshape(-1, H, W)   # (N, H, W)\n",
        "\n",
        "    # 用 SVD 子空間公式做分類\n",
        "    y_pred, residuals = classify_with_svd_subspaces_formula(subspaces, X_imgs)\n",
        "\n",
        "    return names, y_pred, residuals\n"
      ],
      "metadata": {
        "id": "fczNVogmhmip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"使用 SVD 子空間分類器，對ROI+字變粗的手寫資料重新預測\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# 1) 醫師的手寫（handwrite/dr）\n",
        "dr_names, dr_preds_new, dr_residuals_new = svd_predict_handwrite_folder_3(\n",
        "    'handwrite/dr',\n",
        "    subspaces_best,          # 前面建好的 k=30 子空間\n",
        "    img_size=(16, 16)\n",
        ")\n",
        "\n",
        "print(\"\\n=== handwrite/dr 預測結果 (SVD) ===\")\n",
        "for name, pred, res in zip(dr_names, dr_preds_new, dr_residuals_new):\n",
        "    print(f\"檔名: {name:>6s} -> 預測數字: {pred} (最小 residual: {res:.4f})\")\n",
        "\n",
        "# 2) 我的手寫（handwrite/mine）\n",
        "mine_names, mine_preds_new, mine_residuals_new = svd_predict_handwrite_folder_3(\n",
        "    'handwrite/mine',\n",
        "    subspaces_best,\n",
        "    img_size=(16, 16)\n",
        ")\n",
        "\n",
        "print(\"\\n=== handwrite/mine 預測結果 (SVD) ===\")\n",
        "for name, pred, res in zip(mine_names, mine_preds_new, mine_residuals_new):\n",
        "    print(f\"檔名: {name:>6s} -> 預測數字: {pred} (最小 residual: {res:.4f})\")\n"
      ],
      "metadata": {
        "id": "9NTbKAp5hmiq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dr_correct = sum(\n",
        "    int(name.split('.')[0]) == int(pred)\n",
        "    for name, pred in zip(dr_names, dr_preds_new)\n",
        ")\n",
        "print(f\"dr 正確 {dr_correct} / {len(dr_names)}\")\n",
        "\n",
        "mine_correct = sum(\n",
        "    int(name.split('.')[0]) == int(pred)\n",
        "    for name, pred in zip(mine_names, mine_preds_new)\n",
        ")\n",
        "print(f\"mine 正確 {mine_correct} / {len(mine_names)}\")\n"
      ],
      "metadata": {
        "id": "8yMimO3rhmiq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_preprocessing__3_svd(folder_path, subspaces, n_samples=10, img_size=(16, 16)):\n",
        "\n",
        "    files = sorted([\n",
        "        f for f in os.listdir(folder_path)\n",
        "        if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
        "    ])[:n_samples]\n",
        "\n",
        "    fig, axes = plt.subplots(n_samples, 6, figsize=(18, 3 * n_samples))\n",
        "    if n_samples == 1:\n",
        "        axes = axes.reshape(1, -1)\n",
        "\n",
        "    some_digit = sorted(subspaces.keys())[0]\n",
        "    k_vis = subspaces[some_digit]['Uk'].shape[1]\n",
        "\n",
        "    fig.suptitle(\n",
        "        f'{folder_path}_ROI + gray-dilate + SVD (k={k_vis})',\n",
        "        fontsize=16, fontweight='bold'\n",
        "    )\n",
        "\n",
        "    H, W = img_size\n",
        "    digits = sorted(subspaces.keys())\n",
        "\n",
        "    for idx, filename in enumerate(files):\n",
        "        img_path = os.path.join(folder_path, filename)\n",
        "        gray = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        if gray is None:\n",
        "            continue\n",
        "\n",
        "        # 1. 原始圖片\n",
        "        axes[idx, 0].imshow(gray, cmap='gray')\n",
        "        axes[idx, 0].set_title('1. original img')\n",
        "        axes[idx, 0].axis('off')\n",
        "\n",
        "        # 2. 自動反轉 → 確保白底黑字\n",
        "        if np.mean(gray) < 128:\n",
        "            inv = 255 - gray\n",
        "        else:\n",
        "            inv = gray.copy()\n",
        "        axes[idx, 1].imshow(inv, cmap='gray')\n",
        "        axes[idx, 1].set_title('2.inverse to w bg and black digits')\n",
        "        axes[idx, 1].axis('off')\n",
        "\n",
        "        # 3. 二值化 mask (深色數字 → 白色前景)\n",
        "        _, mask = cv2.threshold(\n",
        "            inv, 0, 255,\n",
        "            cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU\n",
        "        )\n",
        "        axes[idx, 2].imshow(mask, cmap='gray')\n",
        "        axes[idx, 2].set_title('3. binary mask')\n",
        "        axes[idx, 2].axis('off')\n",
        "\n",
        "        # 如果整張都沒有前景，就跳過\n",
        "        if np.count_nonzero(mask) == 0:\n",
        "            continue\n",
        "\n",
        "        # 4. 根據 mask 裁出 ROI（灰階）\n",
        "        ys, xs = np.where(mask > 0)\n",
        "        x_min, x_max = xs.min(), xs.max()\n",
        "        y_min, y_max = ys.min(), ys.max()\n",
        "        roi = inv[y_min:y_max+1, x_min:x_max+1]\n",
        "        axes[idx, 3].imshow(roi, cmap='gray')\n",
        "        axes[idx, 3].set_title('4. Cut out ROI')\n",
        "        axes[idx, 3].axis('off')\n",
        "\n",
        "        # 5. ROI → resize → 在灰階上反轉 + 膨脹 + 再反轉\n",
        "        digit_small = cv2.resize(\n",
        "            roi, img_size,\n",
        "            interpolation=cv2.INTER_AREA\n",
        "        )\n",
        "\n",
        "        inv_small = 255 - digit_small\n",
        "        kernel = np.ones((2, 2), np.uint8)\n",
        "        inv_thick = cv2.dilate(inv_small, kernel, iterations=1)\n",
        "        digit_thick_gray = 255 - inv_thick\n",
        "\n",
        "        digit_thick_gray = cv2.normalize(\n",
        "            digit_thick_gray, None, alpha=0, beta=255,\n",
        "            norm_type=cv2.NORM_MINMAX\n",
        "        )\n",
        "\n",
        "        axes[idx, 4].imshow(digit_thick_gray, cmap='gray')\n",
        "        axes[idx, 4].set_title(f'5. resize + gray-dilate\\n({img_size[0]}x{img_size[1]})')\n",
        "        axes[idx, 4].axis('off')\n",
        "\n",
        "        # 這裡一樣：這張 16x16 灰階 → normalize 到 [0,1] → flatten 給 SVD\n",
        "        img_norm = digit_thick_gray.astype(np.float32) / 255.0\n",
        "        x = img_norm.flatten()  # (D,)\n",
        "\n",
        "        # 6. SVD 子空間預測 + 重建（取最後一欄）\n",
        "        best_digit = None\n",
        "        best_res   = None\n",
        "        best_recon = None\n",
        "\n",
        "        for d in digits:\n",
        "            mean_c = subspaces[d]['mean']   # (D,)\n",
        "            Uk     = subspaces[d]['Uk']     # (D, k)\n",
        "\n",
        "            z = x - mean_c\n",
        "            coeff = Uk.T @ z\n",
        "            proj  = Uk @ coeff\n",
        "            res_vec = z - proj\n",
        "            residual = np.linalg.norm(res_vec, ord=2)\n",
        "\n",
        "            if (best_res is None) or (residual < best_res):\n",
        "                best_res   = residual\n",
        "                best_digit = d\n",
        "                best_recon = mean_c + proj\n",
        "\n",
        "        if best_recon is not None:\n",
        "            recon_img = best_recon.reshape(H, W)\n",
        "            axes[idx, 5].imshow(recon_img, cmap='gray')\n",
        "            axes[idx, 5].set_title(\n",
        "                f'6. SVD recon\\npred:{best_digit}, r={best_res:.3f}'\n",
        "            )\n",
        "            axes[idx, 5].axis('off')\n",
        "\n",
        "    plt.tight_layout(rect=[0.0, 0, 1, 0.99])\n",
        "    plt.show()\n",
        "visualize_preprocessing__3_svd('handwrite/dr',   subspaces_best, n_samples=10, img_size=(16, 16))\n",
        "visualize_preprocessing__3_svd('handwrite/mine', subspaces_best, n_samples=10, img_size=(16, 16))\n"
      ],
      "metadata": {
        "id": "zCJBsfAGfS06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 方法三 :HOSVD"
      ],
      "metadata": {
        "id": "EZtRBBo024vl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 從 usps_inverted/train 或 test 載入資料，回傳 (N,16,16)、(N,)\n",
        "X_train_imgs, y_train = load_usps_split('usps_inverted/train', img_size=(16,16))\n",
        "X_test_imgs,  y_test  = load_usps_split('usps_inverted/test',  img_size=(16,16))\n"
      ],
      "metadata": {
        "id": "Oiiu2UxL24Sk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unfold(tensor, mode):\n",
        "    return np.reshape(np.moveaxis(tensor, mode, 0),\n",
        "                      (tensor.shape[mode], -1))\n",
        "\n",
        "def mode_n_product(tensor, matrix, mode):\n",
        "    X = np.moveaxis(tensor, mode, 0)      # (I_mode, ...)\n",
        "    shape_rest = X.shape[1:]\n",
        "    X_2d = X.reshape(X.shape[0], -1)      # (I_mode, prod(rest))\n",
        "    Y_2d = matrix @ X_2d                  # (J, prod(rest))\n",
        "    Y = Y_2d.reshape((matrix.shape[0],) + shape_rest)\n",
        "    return np.moveaxis(Y, 0, mode)\n",
        "\n",
        "def hosvd_3d_truncated(A, r1=None, r2=None, r3=None):\n",
        "\n",
        "    I1, I2, I3 = A.shape\n",
        "\n",
        "    # mode-1\n",
        "    A1 = unfold(A, 0)\n",
        "    U1, _, _ = np.linalg.svd(A1, full_matrices=False)\n",
        "    if r1 is not None:\n",
        "        U1 = U1[:, :r1]\n",
        "\n",
        "    # mode-2\n",
        "    A2 = unfold(A, 1)\n",
        "    U2, _, _ = np.linalg.svd(A2, full_matrices=False)\n",
        "    if r2 is not None:\n",
        "        U2 = U2[:, :r2]\n",
        "\n",
        "    # mode-3\n",
        "    A3 = unfold(A, 2)\n",
        "    U3, _, _ = np.linalg.svd(A3, full_matrices=False)\n",
        "    if r3 is not None:\n",
        "        U3 = U3[:, :r3]\n",
        "\n",
        "    # core\n",
        "    S = mode_n_product(A, U1.T, 0)\n",
        "    S = mode_n_product(S, U2.T, 1)\n",
        "    S = mode_n_product(S, U3.T, 2)\n",
        "\n",
        "    return U1, U2, U3, S\n"
      ],
      "metadata": {
        "id": "3rdobrNv3Acx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_hosvd_subspaces_per_digit_truncated(train_imgs, train_labels,r1=8, r2=8, r3=10):\n",
        "\n",
        "    H, W = train_imgs.shape[1], train_imgs.shape[2]\n",
        "    D = H * W\n",
        "    hosvd_spaces = {}\n",
        "\n",
        "    print(\"\\n=== 建立每個 digit 的 HOSVD 子空間 (truncated) ===\")\n",
        "\n",
        "    for d in range(10):\n",
        "        idx = np.where(train_labels == d)[0]\n",
        "        if len(idx) == 0:\n",
        "            print(f\"digit {d}: 沒訓練資料，略過\")\n",
        "            continue\n",
        "\n",
        "        A_digit = np.stack(train_imgs[idx], axis=2)   # (H, W, n_c)\n",
        "        print(f\"\\nDigit {d}: n_c = {A_digit.shape[2]}\")\n",
        "\n",
        "        # 截斷 rank 的 HOSVD\n",
        "        U1, U2, U3, S = hosvd_3d_truncated(A_digit, r1=r1, r2=r2, r3=r3)\n",
        "\n",
        "        r1_eff, r2_eff, r3_eff = S.shape\n",
        "        print(f\"  real core shape S: {S.shape} (r1={r1_eff}, r2={r2_eff}, r3={r3_eff})\")\n",
        "\n",
        "        basis_list = []\n",
        "        norm2_list = []\n",
        "\n",
        "        for j in range(r3_eff):\n",
        "            core_j = S[:, :, j]        # (r1_eff, r2_eff)\n",
        "            Aj = U1 @ core_j @ U2.T    # (H, W)\n",
        "            Aj_flat = Aj.reshape(-1)   # (D,)\n",
        "\n",
        "            norm2 = np.sum(Aj_flat ** 2) + 1e-12  # = <Aj,Aj> = ||Aj||_F^2\n",
        "\n",
        "            basis_list.append(Aj_flat)\n",
        "            norm2_list.append(norm2)\n",
        "\n",
        "        basis = np.stack(basis_list, axis=0)       # (r3_eff, D)\n",
        "        norm2 = np.array(norm2_list)               # (r3_eff,)\n",
        "\n",
        "        hosvd_spaces[d] = {\n",
        "            'basis': basis,\n",
        "            'norm2': norm2\n",
        "        }\n",
        "\n",
        "        print(f\"  digit {d}: 建立 {basis.shape[0]} 個 basis\")\n",
        "\n",
        "    return hosvd_spaces"
      ],
      "metadata": {
        "id": "MaQ63D6Npx3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_hosvd_subspaces_per_digit_truncated(train_imgs, train_labels,r1=8, r2=8, r3=10):\n",
        "\n",
        "    H, W = train_imgs.shape[1], train_imgs.shape[2]\n",
        "    D = H * W\n",
        "    hosvd_spaces = {}\n",
        "\n",
        "    print(\"\\n=== 建立每個 digit 的 HOSVD 子空間 (truncated) ===\")\n",
        "\n",
        "    for d in range(10):\n",
        "        idx = np.where(train_labels == d)[0]\n",
        "        if len(idx) == 0:\n",
        "            print(f\"digit {d}: 沒訓練資料，略過\")\n",
        "            continue\n",
        "\n",
        "        # 把該 digit 的影像堆成 3D 張量 (H, W, n_c)\n",
        "        A_digit = np.stack(train_imgs[idx], axis=2)\n",
        "        print(f\"\\nDigit {d}: n_c = {A_digit.shape[2]}\")\n",
        "\n",
        "        # 截斷 rank 的 HOSVD\n",
        "        U1, U2, U3, S = hosvd_3d_truncated(A_digit, r1=r1, r2=r2, r3=r3)\n",
        "\n",
        "        r1_eff, r2_eff, r3_eff = S.shape\n",
        "        print(f\"  實際 core 形狀 S: {S.shape} (r1={r1_eff}, r2={r2_eff}, r3={r3_eff})\")\n",
        "\n",
        "        basis_list = []\n",
        "        norm2_list = []\n",
        "\n",
        "        for j in range(r3_eff):\n",
        "            core_j = S[:, :, j]        # (r1_eff, r2_eff)\n",
        "\n",
        "            # Aj = U^{(1)} * S(:,:,j) * U^{(2)T}，大小 (H, W)\n",
        "            Aj = U1 @ core_j @ U2.T\n",
        "            Aj_flat = Aj.reshape(-1).astype(np.float64)   # (D,)\n",
        "\n",
        "            # <Aj,Aj> = ||Aj||_F^2\n",
        "            norm2 = np.sum(Aj_flat ** 2) + 1e-12\n",
        "\n",
        "            basis_list.append(Aj_flat)\n",
        "            norm2_list.append(norm2)\n",
        "\n",
        "        basis = np.stack(basis_list, axis=0)     # (r3_eff, D)\n",
        "        norm2 = np.array(norm2_list)             # (r3_eff,)\n",
        "\n",
        "        hosvd_spaces[d] = {\n",
        "            'basis': basis,\n",
        "            'norm2': norm2\n",
        "        }\n",
        "\n",
        "        print(f\"  digit {d}: 建立 {basis.shape[0]} 個 basis\")\n",
        "\n",
        "    return hosvd_spaces\n"
      ],
      "metadata": {
        "id": "cFYp3PbRp-0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_with_hosvd_subspaces(hosvd_spaces, test_imgs):\n",
        "\n",
        "    H, W = test_imgs.shape[1], test_imgs.shape[2]\n",
        "    D = H * W\n",
        "\n",
        "    X_test_flat = test_imgs.reshape(test_imgs.shape[0], D).astype(np.float64)\n",
        "    N_test = X_test_flat.shape[0]\n",
        "\n",
        "    y_pred = []\n",
        "    G_all = np.full((N_test, 10), np.inf, dtype=np.float64)\n",
        "\n",
        "    print(\"\\n=== 使用 HOSVD 子空間進行分類（內積 + 重建誤差） ===\")\n",
        "\n",
        "    for i, z_flat in enumerate(X_test_flat):\n",
        "\n",
        "        best_digit = None\n",
        "        best_G = None\n",
        "\n",
        "        for d in range(10):\n",
        "            if d not in hosvd_spaces:\n",
        "                continue\n",
        "\n",
        "            basis = hosvd_spaces[d]['basis']   # (J, D)，第 j 列是 Aj_flat\n",
        "            norm2 = hosvd_spaces[d]['norm2']   # (J,)，norm2[j] = <Aj,Aj>\n",
        "\n",
        "            # inner[j] = <Z, A_j>\n",
        "            inner = basis @ z_flat             # (J,)\n",
        "\n",
        "            # z_j = <Z,A_j> / <A_j,A_j>\n",
        "            coef  = inner / norm2              # (J,)\n",
        "\n",
        "            # Σ_j z_j A_j\n",
        "            recon_flat = (coef[:, None] * basis).sum(axis=0)  # (D,)\n",
        "\n",
        "            # G = ||Z - Σ_j z_j A_j||_F\n",
        "            diff = z_flat - recon_flat\n",
        "            G = np.linalg.norm(diff)           # 向量 2-norm = Frobenius norm\n",
        "\n",
        "            G_all[i, d] = G\n",
        "\n",
        "            if (best_G is None) or (G < best_G):\n",
        "                best_G = G\n",
        "                best_digit = d\n",
        "\n",
        "        y_pred.append(best_digit)\n",
        "\n",
        "        if (i + 1) % 200 == 0 or (i + 1) == N_test:\n",
        "            print(f\"  已完成 {i+1}/{N_test}\")\n",
        "\n",
        "    return np.array(y_pred), G_all\n"
      ],
      "metadata": {
        "id": "kDDRp-Utp-xd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "def main_hosvd_truncated():\n",
        "    IMG_SIZE = (16, 16)\n",
        "\n",
        "    X_train_imgs, y_train = load_usps_split('usps_inverted/train', img_size=IMG_SIZE)\n",
        "    X_test_imgs,  y_test  = load_usps_split('usps_inverted/test',  img_size=IMG_SIZE)\n",
        "\n",
        "    # 可以調整 r1, r2, r3\n",
        "    hosvd_spaces = build_hosvd_subspaces_per_digit_truncated(\n",
        "        X_train_imgs, y_train,\n",
        "        r1=12, r2=12, r3=15\n",
        "    )\n",
        "\n",
        "    y_pred, G_all = predict_with_hosvd_subspaces(hosvd_spaces, X_test_imgs)\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    print(\"\\n=== HOSVD 手寫數字辨識結果（truncated） ===\")\n",
        "    print(\"Accuracy:\", acc)\n",
        "\n",
        "    print(\"\\n分類報告：\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    print(\"Confusion Matrix：\")\n",
        "    print(cm)\n",
        "\n",
        "    return y_test, y_pred, cm\n",
        "\n",
        "\n",
        "y_test, y_pred, cm = main_hosvd_truncated()"
      ],
      "metadata": {
        "id": "xMsZiMQas9Ax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D  # 只是啟用 3D 投影\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 想要掃的 rank 組合\n",
        "r1_list = [4, 8, 12]\n",
        "r2_list = [4, 8, 12]\n",
        "r3_list = [5, 10, 15]\n",
        "\n",
        "results = []\n",
        "\n",
        "for r1 in r1_list:\n",
        "    for r2 in r2_list:\n",
        "        for r3 in r3_list:\n",
        "            print(\"\\n\" + \"=\"*60)\n",
        "            print(f\"現在測試 HOSVD rank: r1={r1}, r2={r2}, r3={r3}\")\n",
        "            print(\"=\"*60)\n",
        "\n",
        "            hosvd_spaces = build_hosvd_subspaces_per_digit_truncated(\n",
        "                X_train_imgs, y_train,\n",
        "                r1=r1, r2=r2, r3=r3\n",
        "            )\n",
        "\n",
        "            y_pred, _ = predict_with_hosvd_subspaces(hosvd_spaces, X_test_imgs)\n",
        "            acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "            print(f\"Accuracy = {acc:.4f}\")\n",
        "\n",
        "            results.append({\n",
        "                'r1': r1,\n",
        "                'r2': r2,\n",
        "                'r3': r3,\n",
        "                'accuracy': acc\n",
        "            })\n",
        "\n",
        "df = pd.DataFrame(results)\n",
        "print(\"\\n=== 各種 (r1,r2,r3) 的 accuracy ===\")\n",
        "print(df.sort_values('accuracy', ascending=False).reset_index(drop=True))\n"
      ],
      "metadata": {
        "id": "m9hghbtH4fMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "def visualize_confusion_matrix_results(cm, accuracy, method_name='HOSVD'):\n",
        "    plt.figure(figsize=(20, 12))\n",
        "    sns.heatmap(cm,\n",
        "                annot=True,\n",
        "                fmt='d',\n",
        "                cmap='Blues',\n",
        "                xticklabels=range(10),\n",
        "                yticklabels=range(10))\n",
        "\n",
        "    plt.title(f'Confusion Matrix - {method_name} Method\\nAccuracy: {accuracy*100:.2f}%',\n",
        "              fontsize=14, fontweight='bold')\n",
        "    plt.xlabel('Predicted Label', fontsize=12)\n",
        "    plt.ylabel('True Label', fontsize=12)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'ConfusionMatrix_{method_name}.png', dpi=150, bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "\n",
        "visualize_confusion_matrix_results(cm, acc, method_name='HOSVD')\n"
      ],
      "metadata": {
        "id": "G-k53mePr-mT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "IMG_SIZE = (16, 16)\n",
        "H, W = IMG_SIZE\n",
        "\n",
        "# 1. 載入 USPS train / test\n",
        "X_train_imgs, y_train = load_usps_split('usps_inverted/train', img_size=IMG_SIZE)\n",
        "X_test_imgs,  y_test  = load_usps_split('usps_inverted/test',  img_size=IMG_SIZE)\n",
        "\n",
        "# 2. 使用最佳參數建立 HOSVD 子空間\n",
        "best_r1, best_r2, best_r3 = 12, 12, 15\n",
        "\n",
        "hosvd_best = build_hosvd_subspaces_per_digit_truncated(\n",
        "    X_train_imgs, y_train,\n",
        "    r1=best_r1, r2=best_r2, r3=best_r3\n",
        ")\n",
        "\n",
        "# 3. 用最佳參數做一次預測，之後視覺化都用這組\n",
        "y_pred_best, G_all_best = predict_with_hosvd_subspaces(hosvd_best, X_test_imgs)\n",
        "\n",
        "acc_best = accuracy_score(y_test, y_pred_best)\n",
        "print(f\"\\nBest HOSVD (r1={best_r1}, r2={best_r2}, r3={best_r3}) accuracy = {acc_best:.4f}\")\n"
      ],
      "metadata": {
        "id": "io_xdVBo5N__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============ 1. 0–9 各自 subspace 的樣子 ============\n",
        "\n",
        "n_show = 5  # 每個 digit 想顯示幾個 basis\n",
        "\n",
        "for d in range(10):\n",
        "    if d not in hosvd_best:\n",
        "        print(f\"digit {d} 沒有 HOSVD 子空間，略過\")\n",
        "        continue\n",
        "\n",
        "    # 平均影像（從 train 算）\n",
        "    idx = np.where(y_train == d)[0]\n",
        "    mean_img = X_train_imgs[idx].mean(axis=0)   # (16,16)\n",
        "\n",
        "    basis = hosvd_best[d]['basis']    # (J, D) = (r3_eff, 256)\n",
        "    J = basis.shape[0]\n",
        "    n_use = min(n_show, J)\n",
        "\n",
        "    fig, axes = plt.subplots(1, n_use + 1,\n",
        "                             figsize=(2.5 * (n_use + 1), 2.5))\n",
        "\n",
        "    # [0] 平均影像\n",
        "    axes[0].imshow(mean_img, cmap='gray')\n",
        "    axes[0].set_title(f'{d} mean')\n",
        "    axes[0].axis('off')\n",
        "\n",
        "    # 之後幾張：前幾個 HOSVD basis\n",
        "    for j in range(n_use):\n",
        "        basis_img = basis[j].reshape(H, W)\n",
        "        axes[j + 1].imshow(basis_img, cmap='gray')\n",
        "        axes[j + 1].set_title(f'basis {j+1}')\n",
        "        axes[j + 1].axis('off')\n",
        "\n",
        "    plt.suptitle(f'HOSVD subspace for digit {d}\\n(r1={best_r1}, r2={best_r2}, r3={best_r3})')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "TNpJb_Dv62NB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============ 預測錯誤的前5個測試影像 ============\n",
        "\n",
        "mis_idx = np.where(y_pred_best != y_test)[0]\n",
        "\n",
        "if len(mis_idx) == 0:\n",
        "    print(\"No wrong\")\n",
        "else:\n",
        "    top_idx = mis_idx[:5]\n",
        "    n = len(top_idx)\n",
        "\n",
        "    cols = 5\n",
        "    rows = math.ceil(n / cols)\n",
        "\n",
        "    fig, axes = plt.subplots(rows, cols, figsize=(3 * cols, 3 * rows))\n",
        "    axes = np.array(axes).reshape(-1)\n",
        "\n",
        "    for ax_i, idx in enumerate(top_idx):\n",
        "        axes[ax_i].imshow(X_test_imgs[idx], cmap='gray')\n",
        "        axes[ax_i].set_title(f\"true {y_test[idx]} → pred {y_pred_best[idx]}\")\n",
        "        axes[ax_i].axis('off')\n",
        "\n",
        "    for j in range(n, rows * cols):\n",
        "        axes[j].axis('off')\n",
        "\n",
        "    plt.suptitle(f\"HOSVD (r1={best_r1}, r2={best_r2}, r3={best_r3})top wrong predict {n} test sample\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "G4hf1AMX64cF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def residual_norm_hosvd(z_flat, basis, norm2):\n",
        "\n",
        "    # <Z, A_j>\n",
        "    inner = basis @ z_flat          # (J,)\n",
        "\n",
        "    # z_j\n",
        "    coef = inner / norm2            # (J,)\n",
        "\n",
        "    # Σ_j z_j A_j\n",
        "    recon_flat = (coef[:, None] * basis).sum(axis=0)  # (D,)\n",
        "\n",
        "    diff = z_flat - recon_flat\n",
        "    G = np.linalg.norm(diff)\n",
        "    return G\n"
      ],
      "metadata": {
        "id": "4zJ9hozhujFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_residual_confusion_hosvd(digit, test_imgs, y_test, hosvd_spaces):\n",
        "\n",
        "    N_test = test_imgs.shape[0]\n",
        "    H, W   = test_imgs.shape[1], test_imgs.shape[2]\n",
        "    D      = H * W\n",
        "\n",
        "    # flatten 測試影像\n",
        "    X_test_flat = test_imgs.reshape(N_test, D).astype(np.float64)\n",
        "\n",
        "    # 找出所有真實標籤是 digit 的樣本 index\n",
        "    digit_indices = np.where(y_test == digit)[0]\n",
        "    print(f\"\\n[HOSVD] 分析數字 {digit} 的 residual 分佈 (共 {len(digit_indices)} 個樣本)\")\n",
        "\n",
        "    digits = sorted(hosvd_spaces.keys())  # 通常是 0~9\n",
        "\n",
        "    # 收集每一個樣本的 residual 曲線\n",
        "    all_residuals = []\n",
        "\n",
        "    for idx in digit_indices:\n",
        "        z_flat = X_test_flat[idx]\n",
        "        residuals_to_all = []\n",
        "\n",
        "        for d in digits:\n",
        "            basis_d = hosvd_spaces[d]['basis']  # (J, D)\n",
        "            norm2_d = hosvd_spaces[d]['norm2']  # (J,)\n",
        "\n",
        "            r = residual_norm_hosvd(z_flat, basis_d, norm2_d)\n",
        "            residuals_to_all.append(r)\n",
        "\n",
        "        all_residuals.append(residuals_to_all)\n",
        "\n",
        "    all_residuals = np.array(all_residuals)   # (N_samples_digit, 10)\n",
        "\n",
        "    # --- 畫圖 ---\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # 每個樣本一條藍線\n",
        "    for r in all_residuals:\n",
        "        plt.plot(digits, r, alpha=0.2, color='blue')\n",
        "\n",
        "    # 平均 residual（紅線）\n",
        "    avg_residuals = all_residuals.mean(axis=0)\n",
        "    plt.plot(digits, avg_residuals, 'r-', linewidth=3, label='mean residual')\n",
        "\n",
        "    plt.xlabel('Digit subspace', fontsize=12)\n",
        "    plt.ylabel(r'HOSVD residual norm $ \\| Z - \\sum_j z_j A_j \\|_2 $', fontsize=12)\n",
        "    plt.title(f'HOSVD residual of true digit {digit} to all digit subspaces',\n",
        "              fontsize=14, fontweight='bold')\n",
        "    plt.xticks(digits)\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # --- 找最容易混淆 / 最不像的類別（依平均 residual）---\n",
        "    avg_for_arg = avg_residuals.copy()\n",
        "\n",
        "    # 把自己那類先設成 inf，只考慮其他類\n",
        "    self_idx = digits.index(digit)\n",
        "    avg_for_arg[self_idx] = np.inf\n",
        "\n",
        "    confused_idx = np.argmin(avg_for_arg)\n",
        "    worst_idx    = np.argmax(avg_for_arg)\n",
        "\n",
        "    confused_with = digits[confused_idx]\n",
        "    worst_with    = digits[worst_idx]\n",
        "\n",
        "    print(f\"數字 {digit} 最容易被混淆為: {confused_with} (平均 residual = {avg_residuals[confused_idx]:.4f})\")\n",
        "    print(f\"數字 {digit} 最不像的是: {worst_with} (平均 residual = {avg_residuals[worst_idx]:.4f})\")\n"
      ],
      "metadata": {
        "id": "Mm01YhnlujBK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = (16, 16)\n",
        "\n",
        "# 讀資料\n",
        "X_train_imgs, y_train = load_usps_split('usps_inverted/train', img_size=IMG_SIZE)\n",
        "X_test_imgs,  y_test  = load_usps_split('usps_inverted/test',  img_size=IMG_SIZE)\n",
        "\n",
        "# 建立「最佳」 HOSVD 子空間 (r1=12, r2=12, r3=15)\n",
        "hosvd_spaces_best = build_hosvd_subspaces_per_digit_truncated(\n",
        "    X_train_imgs, y_train,\n",
        "    r1=12, r2=12, r3=15\n",
        ")\n",
        "\n",
        "# 想確認一下這組 rank 的 accuracy 也可以順便算\n",
        "y_pred_best, G_all_best = predict_with_hosvd_subspaces(hosvd_spaces_best, X_test_imgs)\n",
        "acc_best = accuracy_score(y_test, y_pred_best)\n",
        "print(\"Best HOSVD (12,12,15) accuracy:\", acc_best)\n",
        "\n",
        "# 畫幾個代表性的數字的 residual 圖\n",
        "visualize_residual_confusion_hosvd(0, X_test_imgs, y_test, hosvd_spaces_best)\n",
        "visualize_residual_confusion_hosvd(1, X_test_imgs, y_test, hosvd_spaces_best)\n",
        "visualize_residual_confusion_hosvd(5, X_test_imgs, y_test, hosvd_spaces_best)\n",
        "visualize_residual_confusion_hosvd(7, X_test_imgs, y_test, hosvd_spaces_best)\n"
      ],
      "metadata": {
        "id": "tUz-VA16ui9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##方法三:HOSVD_自己手寫預測"
      ],
      "metadata": {
        "id": "PzTDhBhL7gYd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 建立 Best HOSVD 子空間 (r1=12, r2=12, r3=15)\n",
        "# ==========================================\n",
        "\n",
        "TRAIN_PATH = 'usps_inverted/train'\n",
        "img_size   = (16, 16)\n",
        "\n",
        "# 1. 載入訓練資料\n",
        "X_train_imgs, y_train = load_usps_split(TRAIN_PATH, img_size=img_size)\n",
        "\n",
        "# 2. 建立 HOSVD 子空間（Best: r1=12, r2=12, r3=15）\n",
        "hosvd_best = build_hosvd_subspaces_per_digit_truncated(\n",
        "    X_train_imgs, y_train,\n",
        "    r1=12, r2=12, r3=15\n",
        ")\n"
      ],
      "metadata": {
        "id": "B7-WcfQ_xz0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.手寫字_原始版(無框ROI+無字體加粗)\n"
      ],
      "metadata": {
        "id": "j4S2M8qexP-q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def hosvd_predict_handwrite_folder(folder_path, hosvd_spaces, img_size=(16, 16)):\n",
        "\n",
        "    # 使用原本的前處理\n",
        "    X_flat, names = load_handwrite_original(folder_path, img_size=img_size)  # (N, 256)\n",
        "\n",
        "    # 轉回 (N, H, W) 給 HOSVD 分類器使用\n",
        "    H, W = img_size\n",
        "    X_imgs = X_flat.reshape(-1, H, W)   # (N, H, W)\n",
        "\n",
        "    # 用 HOSVD 子空間公式做分類\n",
        "    y_pred, G_all = predict_with_hosvd_subspaces(hosvd_spaces, X_imgs)\n",
        "    # 每張圖在 10 個 digit 子空間的 G 值，取最小的當作該圖的 residual 指標\n",
        "    min_residual = G_all.min(axis=1)\n",
        "\n",
        "    return names, y_pred, min_residual"
      ],
      "metadata": {
        "id": "afEl98v-xazA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 對 handwrite/dr & handwrite/mine 做預測並統計\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"使用 HOSVD 子空間分類器，對手寫資料重新預測\")\n",
        "print(\"Best HOSVD (r1=12, r2=12, r3=15)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# 1) 醫師的手寫（handwrite/dr）\n",
        "dr_names, dr_preds_new, dr_residuals_new = hosvd_predict_handwrite_folder(\n",
        "    'handwrite/dr',\n",
        "    hosvd_best,          # 上面建好的 best HOSVD 子空間\n",
        "    img_size=(16, 16)\n",
        ")\n",
        "\n",
        "print(\"\\n=== handwrite/dr 預測結果 (HOSVD) ===\")\n",
        "for name, pred, res in zip(dr_names, dr_preds_new, dr_residuals_new):\n",
        "    print(f\"檔名: {name:>6s} -> 預測數字: {pred} (最小 residual: {res:.4f})\")\n",
        "\n",
        "# 2) 我的手寫（handwrite/mine）\n",
        "mine_names, mine_preds_new, mine_residuals_new = hosvd_predict_handwrite_folder(\n",
        "    'handwrite/mine',\n",
        "    hosvd_best,\n",
        "    img_size=(16, 16)\n",
        ")\n",
        "\n",
        "print(\"\\n=== handwrite/mine 預測結果 (HOSVD) ===\")\n",
        "for name, pred, res in zip(mine_names, mine_preds_new, mine_residuals_new):\n",
        "    print(f\"檔名: {name:>6s} -> 預測數字: {pred} (最小 residual: {res:.4f})\")\n",
        "\n"
      ],
      "metadata": {
        "id": "aNFohlRSxawO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dr_correct = sum(\n",
        "    int(name.split('.')[0]) == int(pred)\n",
        "    for name, pred in zip(dr_names, dr_preds_new)\n",
        ")\n",
        "print(f\"\\ndr 正確 {dr_correct} / {len(dr_names)}\")\n",
        "\n",
        "mine_correct = sum(\n",
        "    int(name.split('.')[0]) == int(pred)\n",
        "    for name, pred in zip(mine_names, mine_preds_new)\n",
        ")\n",
        "print(f\"mine 正確 {mine_correct} / {len(mine_names)}\")"
      ],
      "metadata": {
        "id": "-f7p4ZKIxatI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def visualize_preprocessing_hosvd(folder_path, hosvd_spaces,n_samples=10, img_size=(16, 16),ranks=(12, 12, 15)):\n",
        "\n",
        "\n",
        "    # 取得每個 digit 子空間的 basis 數量 J（= r3_eff）\n",
        "    some_digit = sorted(hosvd_spaces.keys())[0]\n",
        "    J_vis = hosvd_spaces[some_digit]['basis'].shape[0]\n",
        "\n",
        "    files = sorted([\n",
        "        f for f in os.listdir(folder_path)\n",
        "        if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
        "    ])[:n_samples]\n",
        "\n",
        "    fig, axes = plt.subplots(n_samples, 4, figsize=(12, 3 * n_samples))\n",
        "    if n_samples == 1:\n",
        "        axes = axes.reshape(1, -1)\n",
        "\n",
        "    r1, r2, r3 = ranks\n",
        "    fig.suptitle(\n",
        "        f'{folder_path} - HOSVD preprocessing & prediction\\n'\n",
        "        f'Best HOSVD (r1={r1}, r2={r2}, r3={r3}), J={J_vis}',\n",
        "        fontsize=18,\n",
        "        fontweight='bold'\n",
        "    )\n",
        "\n",
        "    H, W = img_size\n",
        "    digits = sorted(hosvd_spaces.keys())\n",
        "\n",
        "    for idx, filename in enumerate(files):\n",
        "        img_path = os.path.join(folder_path, filename)\n",
        "        gray = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "        if gray is None:\n",
        "            continue\n",
        "\n",
        "        # 1. 原始圖片\n",
        "        axes[idx, 0].imshow(gray, cmap='gray')\n",
        "        axes[idx, 0].set_title('1. original img')\n",
        "        axes[idx, 0].axis('off')\n",
        "\n",
        "        # 2. 自動反轉\n",
        "        if np.mean(gray) < 128:\n",
        "            inv = 255 - gray   # 偏暗視為黑底白字 → 反轉\n",
        "        else:\n",
        "            inv = gray.copy()  # 已是白底黑字，不動\n",
        "\n",
        "        axes[idx, 1].imshow(inv, cmap='gray')\n",
        "        axes[idx, 1].set_title('2. auto invert\\n(white bg, dark digit)')\n",
        "        axes[idx, 1].axis('off')\n",
        "\n",
        "        # 3. 縮放到 img_size，並正規化到 [0,1]\n",
        "        digit_small = cv2.resize(\n",
        "            inv, img_size,\n",
        "            interpolation=cv2.INTER_AREA\n",
        "        )\n",
        "        img_norm = digit_small.astype(np.float32) / 255.0\n",
        "        x = img_norm.flatten().astype(np.float64)  # (D,)\n",
        "\n",
        "        axes[idx, 2].imshow(img_norm, cmap='gray')\n",
        "        axes[idx, 2].set_title(f'3. resize + normalize\\n({img_size[0]}x{img_size[1]})')\n",
        "        axes[idx, 2].axis('off')\n",
        "\n",
        "        # 4. 用 HOSVD 子空間做預測 + 重建\n",
        "        best_digit = None\n",
        "        best_res   = None\n",
        "        best_recon = None\n",
        "\n",
        "        for d in digits:\n",
        "            basis_d = hosvd_spaces[d]['basis']  # (J, D) Aj_flat\n",
        "            norm2_d = hosvd_spaces[d]['norm2']  # (J,)   <Aj,Aj>\n",
        "\n",
        "            # 內積 <x, A_j>\n",
        "            inner = basis_d @ x                # (J,)\n",
        "            # 係數 z_j\n",
        "            coef  = inner / norm2_d            # (J,)\n",
        "            # Σ_j z_j A_j\n",
        "            recon_flat = (coef[:, None] * basis_d).sum(axis=0)  # (D,)\n",
        "\n",
        "            residual = np.linalg.norm(x - recon_flat)\n",
        "\n",
        "            if (best_res is None) or (residual < best_res):\n",
        "                best_res   = residual\n",
        "                best_digit = d\n",
        "                best_recon = recon_flat\n",
        "\n",
        "        if best_recon is not None:\n",
        "            recon_img = best_recon.reshape(H, W)\n",
        "            axes[idx, 3].imshow(recon_img, cmap='gray')\n",
        "            axes[idx, 3].set_title(\n",
        "                f'4. HOSVD recon\\npred:{best_digit}, r={best_res:.3f}'\n",
        "            )\n",
        "            axes[idx, 3].axis('off')\n",
        "\n",
        "    plt.tight_layout(rect=[0.0, 0, 1, 0.93])\n",
        "    plt.show()\n",
        "\n",
        "visualize_preprocessing_hosvd('handwrite/dr',\n",
        "                              hosvd_best,\n",
        "                              n_samples=10,\n",
        "                              img_size=(16, 16),\n",
        "                              ranks=(12, 12, 15))\n",
        "\n",
        "visualize_preprocessing_hosvd('handwrite/mine',\n",
        "                              hosvd_best,\n",
        "                              n_samples=10,\n",
        "                              img_size=(16, 16),\n",
        "                              ranks=(12, 12, 15))"
      ],
      "metadata": {
        "id": "kBV6GcPjzQpZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.手寫字_無框ROI+字體加粗\n"
      ],
      "metadata": {
        "id": "6SmyKdKDxP7r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def hosvd_predict_handwrite_folder_2(folder_path, hosvd_spaces, img_size=(16, 16)):\n",
        "\n",
        "    # 使用字變粗前處理\n",
        "    X_flat, names = load_handwrite_enhanced(folder_path, img_size=img_size)  # (N, 256)\n",
        "\n",
        "    # 轉回 (N, H, W) 給 HOSVD 分類器使用\n",
        "    H, W = img_size\n",
        "    X_imgs = X_flat.reshape(-1, H, W)   # (N, H, W)\n",
        "\n",
        "    # 用 HOSVD 子空間公式做分類\n",
        "    y_pred, G_all = predict_with_hosvd_subspaces(hosvd_spaces, X_imgs)\n",
        "\n",
        "\n",
        "    # 每張圖在 10 個 digit 子空間的 G 值，取最小的當作該圖的 residual 指標\n",
        "    min_residual = G_all.min(axis=1)\n",
        "\n",
        "    return names, y_pred, min_residual"
      ],
      "metadata": {
        "id": "HsD8KhXkyTE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 對 handwrite/dr & handwrite/mine 做預測並統計\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"使用 HOSVD 子空間分類器，對手字變粗寫資料重新預測\")\n",
        "print(\"Best HOSVD (r1=12, r2=12, r3=15)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# 1) 醫師的手寫（handwrite/dr）\n",
        "dr_names, dr_preds_new, dr_residuals_new = hosvd_predict_handwrite_folder_2(\n",
        "    'handwrite/dr',\n",
        "    hosvd_best,          # 上面建好的 best HOSVD 子空間\n",
        "    img_size=(16, 16)\n",
        ")\n",
        "\n",
        "print(\"\\n=== handwrite/dr 預測結果 (HOSVD) ===\")\n",
        "for name, pred, res in zip(dr_names, dr_preds_new, dr_residuals_new):\n",
        "    print(f\"檔名: {name:>6s} -> 預測數字: {pred} (最小 residual: {res:.4f})\")\n",
        "\n",
        "# 2) 我的手寫（handwrite/mine）\n",
        "mine_names, mine_preds_new, mine_residuals_new = hosvd_predict_handwrite_folder_2(\n",
        "    'handwrite/mine',\n",
        "    hosvd_best,\n",
        "    img_size=(16, 16)\n",
        ")\n",
        "\n",
        "print(\"\\n=== handwrite/mine 預測結果 (HOSVD) ===\")\n",
        "for name, pred, res in zip(mine_names, mine_preds_new, mine_residuals_new):\n",
        "    print(f\"檔名: {name:>6s} -> 預測數字: {pred} (最小 residual: {res:.4f})\")\n",
        "\n"
      ],
      "metadata": {
        "id": "DKrQqT-0yTFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dr_correct = sum(\n",
        "    int(name.split('.')[0]) == int(pred)\n",
        "    for name, pred in zip(dr_names, dr_preds_new)\n",
        ")\n",
        "print(f\"\\ndr 正確 {dr_correct} / {len(dr_names)}\")\n",
        "\n",
        "mine_correct = sum(\n",
        "    int(name.split('.')[0]) == int(pred)\n",
        "    for name, pred in zip(mine_names, mine_preds_new)\n",
        ")\n",
        "print(f\"mine 正確 {mine_correct} / {len(mine_names)}\")"
      ],
      "metadata": {
        "id": "_nHJixyKyTFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def visualize_preprocessing__2_hosvd(folder_path, hosvd_spaces,n_samples=10, img_size=(16, 16),ranks=(12, 12, 15)):\n",
        "\n",
        "    files = sorted([\n",
        "        f for f in os.listdir(folder_path)\n",
        "        if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
        "    ])[:n_samples]\n",
        "\n",
        "    fig, axes = plt.subplots(n_samples, 4, figsize=(12, 3 * n_samples))\n",
        "    if n_samples == 1:\n",
        "        axes = axes.reshape(1, -1)\n",
        "\n",
        "    # 取一個 digit 看 basis (J) 的大小\n",
        "    some_digit = sorted(hosvd_spaces.keys())[0]\n",
        "    J_vis = hosvd_spaces[some_digit]['basis'].shape[0]\n",
        "\n",
        "    r1, r2, r3 = ranks\n",
        "    fig.suptitle(\n",
        "        f'{folder_path}_Image preprocessing (dilate) + '\n",
        "        f'HOSVD (r1={r1}, r2={r2}, r3={r3}, J={J_vis})',\n",
        "        fontsize=16, fontweight='bold'\n",
        "    )\n",
        "\n",
        "    H, W = img_size\n",
        "    digits = sorted(hosvd_spaces.keys())\n",
        "\n",
        "    for idx, filename in enumerate(files):\n",
        "        img_path = os.path.join(folder_path, filename)\n",
        "        gray = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        if gray is None:\n",
        "            continue\n",
        "\n",
        "        # 1. 原始圖片\n",
        "        axes[idx, 0].imshow(gray, cmap='gray')\n",
        "        axes[idx, 0].set_title('1. original img')\n",
        "        axes[idx, 0].axis('off')\n",
        "\n",
        "        # 2. 自動反轉\n",
        "        if np.mean(gray) < 128:\n",
        "            inv = 255 - gray\n",
        "        else:\n",
        "            inv = gray.copy()\n",
        "\n",
        "        axes[idx, 1].imshow(inv, cmap='gray')\n",
        "        axes[idx, 1].set_title('2. auto invert\\n(white bg, dark digit)')\n",
        "        axes[idx, 1].axis('off')\n",
        "\n",
        "        # 3. 縮放 + 灰階膨脹 (加粗筆畫)\n",
        "        digit_small = cv2.resize(\n",
        "            inv, img_size,\n",
        "            interpolation=cv2.INTER_AREA\n",
        "        )\n",
        "\n",
        "        # 反轉 + 膨脹 + 再反轉\n",
        "        inv_small = 255 - digit_small\n",
        "        kernel = np.ones((2, 2), np.uint8)\n",
        "        inv_thick = cv2.dilate(inv_small, kernel, iterations=1)\n",
        "        digit_thick_gray = 255 - inv_thick\n",
        "\n",
        "        # 對比拉伸\n",
        "        digit_thick_gray = cv2.normalize(\n",
        "            digit_thick_gray, None, alpha=0, beta=255,\n",
        "            norm_type=cv2.NORM_MINMAX\n",
        "        )\n",
        "\n",
        "        axes[idx, 2].imshow(digit_thick_gray, cmap='gray')\n",
        "        axes[idx, 2].set_title(\n",
        "            f'3. resize + gray-dilate\\n({img_size[0]}x{img_size[1]})'\n",
        "        )\n",
        "        axes[idx, 2].axis('off')\n",
        "\n",
        "        # 丟進 HOSVD 分類器的輸入：normalize 到 [0,1] 後 flatten\n",
        "        img_norm = digit_thick_gray.astype(np.float32) / 255.0\n",
        "        x = img_norm.flatten().astype(np.float64)  # (D,)\n",
        "\n",
        "        # 4. 用 HOSVD 子空間做預測 + 重建\n",
        "        best_digit = None\n",
        "        best_res   = None\n",
        "        best_recon = None\n",
        "\n",
        "        for d in digits:\n",
        "            basis_d = hosvd_spaces[d]['basis']  # (J, D)\n",
        "            norm2_d = hosvd_spaces[d]['norm2']  # (J,)\n",
        "\n",
        "            inner = basis_d @ x                # <x, A_j>\n",
        "            coef  = inner / norm2_d            # z_j\n",
        "            recon_flat = (coef[:, None] * basis_d).sum(axis=0)  # Σ z_j A_j\n",
        "\n",
        "            residual = np.linalg.norm(x - recon_flat)\n",
        "\n",
        "            if (best_res is None) or (residual < best_res):\n",
        "                best_res   = residual\n",
        "                best_digit = d\n",
        "                best_recon = recon_flat\n",
        "\n",
        "        if best_recon is not None:\n",
        "            recon_img = best_recon.reshape(H, W)\n",
        "            axes[idx, 3].imshow(recon_img, cmap='gray')\n",
        "            axes[idx, 3].set_title(\n",
        "                f'4. HOSVD recon\\npred:{best_digit}, r={best_res:.3f}'\n",
        "            )\n",
        "            axes[idx, 3].axis('off')\n",
        "\n",
        "    plt.tight_layout(rect=[0.0, 0, 1, 0.99])\n",
        "    plt.show()\n",
        "visualize_preprocessing__2_hosvd('handwrite/dr',   hosvd_best,\n",
        "                                 n_samples=10, img_size=(16, 16),\n",
        "                                 ranks=(12, 12, 15))\n",
        "visualize_preprocessing__2_hosvd('handwrite/mine', hosvd_best,\n",
        "                                 n_samples=10, img_size=(16, 16),\n",
        "                                 ranks=(12, 12, 15))\n"
      ],
      "metadata": {
        "id": "CLtexGXov_IG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.手寫字_ROI+字體加粗\n",
        "\n"
      ],
      "metadata": {
        "id": "Gc3USzWbxP33"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def hosvd_predict_handwrite_folder_3(folder_path, hosvd_spaces, img_size=(16, 16)):\n",
        "\n",
        "    # 使用字變粗+ROI的前處理\n",
        "    X_flat, names = load_handwrite_enhanced_ROI(folder_path, img_size=img_size)  # (N, 256)\n",
        "\n",
        "    # 轉回 (N, H, W) 給 HOSVD 分類器使用\n",
        "    H, W = img_size\n",
        "    X_imgs = X_flat.reshape(-1, H, W)   # (N, H, W)\n",
        "\n",
        "    # 用 HOSVD 子空間公式做分類\n",
        "    y_pred, G_all = predict_with_hosvd_subspaces(hosvd_spaces, X_imgs)\n",
        "\n",
        "\n",
        "    # 每張圖在 10 個 digit 子空間的 G 值，取最小的當作該圖的 residual 指標\n",
        "    min_residual = G_all.min(axis=1)\n",
        "\n",
        "    return names, y_pred, min_residual"
      ],
      "metadata": {
        "id": "lVMVZnLWz5KT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 對 handwrite/dr & handwrite/mine 做預測並統計\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"使用 HOSVD 子空間分類器，對字變粗+ROI手寫資料重新預測\")\n",
        "print(\"Best HOSVD (r1=12, r2=12, r3=15)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# 1) 醫師的手寫（handwrite/dr）\n",
        "dr_names, dr_preds_new, dr_residuals_new = hosvd_predict_handwrite_folder_3(\n",
        "    'handwrite/dr',\n",
        "    hosvd_best,          # 上面建好的 best HOSVD 子空間\n",
        "    img_size=(16, 16)\n",
        ")\n",
        "\n",
        "print(\"\\n=== handwrite/dr 預測結果 (HOSVD) ===\")\n",
        "for name, pred, res in zip(dr_names, dr_preds_new, dr_residuals_new):\n",
        "    print(f\"檔名: {name:>6s} -> 預測數字: {pred} (最小 residual: {res:.4f})\")\n",
        "\n",
        "# 2) 我的手寫（handwrite/mine）\n",
        "mine_names, mine_preds_new, mine_residuals_new = hosvd_predict_handwrite_folder_3(\n",
        "    'handwrite/mine',\n",
        "    hosvd_best,\n",
        "    img_size=(16, 16)\n",
        ")\n",
        "\n",
        "print(\"\\n=== handwrite/mine 預測結果 (HOSVD) ===\")\n",
        "for name, pred, res in zip(mine_names, mine_preds_new, mine_residuals_new):\n",
        "    print(f\"檔名: {name:>6s} -> 預測數字: {pred} (最小 residual: {res:.4f})\")\n",
        "\n"
      ],
      "metadata": {
        "id": "fKZyWTdHz5KU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dr_correct = sum(\n",
        "    int(name.split('.')[0]) == int(pred)\n",
        "    for name, pred in zip(dr_names, dr_preds_new)\n",
        ")\n",
        "print(f\"\\ndr 正確 {dr_correct} / {len(dr_names)}\")\n",
        "\n",
        "mine_correct = sum(\n",
        "    int(name.split('.')[0]) == int(pred)\n",
        "    for name, pred in zip(mine_names, mine_preds_new)\n",
        ")\n",
        "print(f\"mine 正確 {mine_correct} / {len(mine_names)}\")"
      ],
      "metadata": {
        "id": "hIplDwLcz5KU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_preprocessing__3_hosvd(folder_path, hosvd_spaces,n_samples=10, img_size=(16, 16),ranks=(12, 12, 15)):\n",
        "\n",
        "    files = sorted([\n",
        "        f for f in os.listdir(folder_path)\n",
        "        if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
        "    ])[:n_samples]\n",
        "\n",
        "    fig, axes = plt.subplots(n_samples, 6, figsize=(18, 3 * n_samples))\n",
        "    if n_samples == 1:\n",
        "        axes = axes.reshape(1, -1)\n",
        "\n",
        "    some_digit = sorted(hosvd_spaces.keys())[0]\n",
        "    J_vis = hosvd_spaces[some_digit]['basis'].shape[0]\n",
        "\n",
        "    r1, r2, r3 = ranks\n",
        "    fig.suptitle(\n",
        "        f'{folder_path}_ROI + gray-dilate + '\n",
        "        f'HOSVD (r1={r1}, r2={r2}, r3={r3}, J={J_vis})',\n",
        "        fontsize=16, fontweight='bold'\n",
        "    )\n",
        "\n",
        "    H, W = img_size\n",
        "    digits = sorted(hosvd_spaces.keys())\n",
        "\n",
        "    for idx, filename in enumerate(files):\n",
        "        img_path = os.path.join(folder_path, filename)\n",
        "        gray = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        if gray is None:\n",
        "            continue\n",
        "\n",
        "        # 1. 原始圖片\n",
        "        axes[idx, 0].imshow(gray, cmap='gray')\n",
        "        axes[idx, 0].set_title('1. original img')\n",
        "        axes[idx, 0].axis('off')\n",
        "\n",
        "        # 2. 自動反轉\n",
        "        if np.mean(gray) < 128:\n",
        "            inv = 255 - gray\n",
        "        else:\n",
        "            inv = gray.copy()\n",
        "        axes[idx, 1].imshow(inv, cmap='gray')\n",
        "        axes[idx, 1].set_title('2. inverse to w bg and black digits')\n",
        "        axes[idx, 1].axis('off')\n",
        "\n",
        "        # 3. 二值化 mask\n",
        "        _, mask = cv2.threshold(\n",
        "            inv, 0, 255,\n",
        "            cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU\n",
        "        )\n",
        "        axes[idx, 2].imshow(mask, cmap='gray')\n",
        "        axes[idx, 2].set_title('3. binary mask')\n",
        "        axes[idx, 2].axis('off')\n",
        "\n",
        "        if np.count_nonzero(mask) == 0:\n",
        "            continue\n",
        "\n",
        "        # 4. 依 mask 裁切 ROI\n",
        "        ys, xs = np.where(mask > 0)\n",
        "        x_min, x_max = xs.min(), xs.max()\n",
        "        y_min, y_max = ys.min(), ys.max()\n",
        "        roi = inv[y_min:y_max+1, x_min:x_max+1]\n",
        "        axes[idx, 3].imshow(roi, cmap='gray')\n",
        "        axes[idx, 3].set_title('4. Cut out ROI')\n",
        "        axes[idx, 3].axis('off')\n",
        "\n",
        "        # 5. ROI → resize → gray-dilate\n",
        "        digit_small = cv2.resize(\n",
        "            roi, img_size,\n",
        "            interpolation=cv2.INTER_AREA\n",
        "        )\n",
        "\n",
        "        inv_small = 255 - digit_small\n",
        "        kernel = np.ones((2, 2), np.uint8)\n",
        "        inv_thick = cv2.dilate(inv_small, kernel, iterations=1)\n",
        "        digit_thick_gray = 255 - inv_thick\n",
        "\n",
        "        digit_thick_gray = cv2.normalize(\n",
        "            digit_thick_gray, None, alpha=0, beta=255,\n",
        "            norm_type=cv2.NORM_MINMAX\n",
        "        )\n",
        "\n",
        "        axes[idx, 4].imshow(digit_thick_gray, cmap='gray')\n",
        "        axes[idx, 4].set_title(\n",
        "            f'5. resize + gray-dilate\\n({img_size[0]}x{img_size[1]})'\n",
        "        )\n",
        "        axes[idx, 4].axis('off')\n",
        "\n",
        "        # normalize → flatten 給 HOSVD\n",
        "        img_norm = digit_thick_gray.astype(np.float32) / 255.0\n",
        "        x = img_norm.flatten().astype(np.float64)  # (D,)\n",
        "\n",
        "        # 6. HOSVD 子空間預測 + 重建\n",
        "        best_digit = None\n",
        "        best_res   = None\n",
        "        best_recon = None\n",
        "\n",
        "        for d in digits:\n",
        "            basis_d = hosvd_spaces[d]['basis']  # (J, D)\n",
        "            norm2_d = hosvd_spaces[d]['norm2']  # (J,)\n",
        "\n",
        "            inner = basis_d @ x                # <x, A_j>\n",
        "            coef  = inner / norm2_d            # z_j\n",
        "            recon_flat = (coef[:, None] * basis_d).sum(axis=0)\n",
        "\n",
        "            residual = np.linalg.norm(x - recon_flat)\n",
        "\n",
        "            if (best_res is None) or (residual < best_res):\n",
        "                best_res   = residual\n",
        "                best_digit = d\n",
        "                best_recon = recon_flat\n",
        "\n",
        "        if best_recon is not None:\n",
        "            recon_img = best_recon.reshape(H, W)\n",
        "            axes[idx, 5].imshow(recon_img, cmap='gray')\n",
        "            axes[idx, 5].set_title(\n",
        "                f'6. HOSVD recon\\npred:{best_digit}, r={best_res:.3f}'\n",
        "            )\n",
        "            axes[idx, 5].axis('off')\n",
        "\n",
        "    plt.tight_layout(rect=[0.0, 0, 1, 0.99])\n",
        "    plt.show()\n",
        "visualize_preprocessing__3_hosvd('handwrite/dr',   hosvd_best,\n",
        "                                 n_samples=10, img_size=(16, 16),\n",
        "                                 ranks=(12, 12, 15))\n",
        "visualize_preprocessing__3_hosvd('handwrite/mine', hosvd_best,\n",
        "                                 n_samples=10, img_size=(16, 16),\n",
        "                                 ranks=(12, 12, 15))"
      ],
      "metadata": {
        "id": "t-Qn-g6lv_Ef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##方法四:Random Forest"
      ],
      "metadata": {
        "id": "yvBoqbbC8hu3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "IMG_SIZE   = (16, 16)\n",
        "TRAIN_PATH = 'usps_inverted/train'\n",
        "TEST_PATH  = 'usps_inverted/test'\n",
        "\n",
        "def train_usps_random_forest(\n",
        "    n_estimators=200,\n",
        "    max_depth=None,\n",
        "    random_state=42\n",
        "):\n",
        "    # 1. 載入 USPS train / test\n",
        "    X_train_imgs, y_train = load_usps_split(TRAIN_PATH, img_size=IMG_SIZE)\n",
        "    X_test_imgs,  y_test  = load_usps_split(TEST_PATH,  img_size=IMG_SIZE)\n",
        "\n",
        "    # 2. 攤平成向量 (N, 256)\n",
        "    H, W = IMG_SIZE\n",
        "    D = H * W\n",
        "\n",
        "    X_train = X_train_imgs.reshape(X_train_imgs.shape[0], D)\n",
        "    X_test  = X_test_imgs.reshape(X_test_imgs.shape[0],  D)\n",
        "\n",
        "    print(\"Train shape :\", X_train.shape)\n",
        "    print(\"Test  shape :\", X_test.shape)\n",
        "\n",
        "    # 3. 建立 RandomForest 分類器\n",
        "    rf = RandomForestClassifier(\n",
        "        n_estimators=n_estimators,\n",
        "        max_depth=max_depth,\n",
        "        n_jobs=-1,\n",
        "        random_state=random_state\n",
        "    )\n",
        "\n",
        "    # 4. 訓練\n",
        "    print(\"\\n開始訓練 USPS RandomForestClassifier ...\")\n",
        "    rf.fit(X_train, y_train)\n",
        "    print(\"訓練完成！\")\n",
        "\n",
        "    # 5. 在 USPS test set 上看一下效果\n",
        "    y_pred = rf.predict(X_test)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    print(\"\\n=== RandomForest 在 USPS 的表現 ===\")\n",
        "    print(\"Accuracy:\", acc)\n",
        "\n",
        "    print(\"\\n分類報告：\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    print(\"Confusion Matrix：\")\n",
        "    print(cm)\n",
        "\n",
        "    # 回傳訓練好的 model，之後拿來對 handwrite/mine、handwrite/dr 用\n",
        "    return rf\n",
        "rf_model = train_usps_random_forest()\n"
      ],
      "metadata": {
        "id": "AErl9GWF88OY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 方法四:RandomForest_自己手寫預測"
      ],
      "metadata": {
        "id": "L1u66v-G-Xhq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.原始字體"
      ],
      "metadata": {
        "id": "eO5pcTZorRq6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rf_predict_handwrite_folder(folder_path, rf_model, img_size=(16, 16)):\n",
        "\n",
        "    X_flat, names = load_handwrite_original(folder_path, img_size=img_size)  # (N, 256)\n",
        "\n",
        "    # 用 RF 做分類\n",
        "    y_pred = rf_model.predict(X_flat)\n",
        "\n",
        "    if hasattr(rf_model, \"predict_proba\"):\n",
        "        proba = rf_model.predict_proba(X_flat)          # (N, n_classes)\n",
        "        max_probs = proba.max(axis=1)                   # (N,)\n",
        "    else:\n",
        "        max_probs = np.full(len(y_pred), np.nan)\n",
        "\n",
        "    return names, y_pred, max_probs\n"
      ],
      "metadata": {
        "id": "ykco7RxIqWPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"使用 RandomForest 分類器，對手寫資料預測\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# 1) 醫師的手寫（handwrite/dr）\n",
        "dr_names, dr_preds_rf, dr_conf_rf = rf_predict_handwrite_folder(\n",
        "    'handwrite/dr',\n",
        "    rf_model,\n",
        "    img_size=(16, 16)\n",
        ")\n",
        "\n",
        "print(\"\\n=== handwrite/dr 預測結果 (RandomForest) ===\")\n",
        "for name, pred, conf in zip(dr_names, dr_preds_rf, dr_conf_rf):\n",
        "    print(f\"檔名: {name:>6s} -> 預測數字: {pred} (confidence: {conf:.3f})\")\n",
        "\n",
        "# 2) 我的手寫（handwrite/mine）\n",
        "mine_names, mine_preds_rf, mine_conf_rf = rf_predict_handwrite_folder(\n",
        "    'handwrite/mine',\n",
        "    rf_model,\n",
        "    img_size=(16, 16)\n",
        ")\n",
        "\n",
        "print(\"\\n=== handwrite/mine 預測結果 (RandomForest) ===\")\n",
        "for name, pred, conf in zip(mine_names, mine_preds_rf, mine_conf_rf):\n",
        "    print(f\"檔名: {name:>6s} -> 預測數字: {pred} (confidence: {conf:.3f})\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DySUGVVkqWML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dr_correct = sum(\n",
        "    int(name.split('.')[0]) == int(pred)\n",
        "    for name, pred in zip(dr_names, dr_preds_rf)\n",
        ")\n",
        "print(f\"\\ndr 正確 {dr_correct} / {len(dr_names)}\")\n",
        "\n",
        "mine_correct = sum(\n",
        "    int(name.split('.')[0]) == int(pred)\n",
        "    for name, pred in zip(mine_names, mine_preds_rf)\n",
        ")\n",
        "print(f\"mine 正確 {mine_correct} / {len(mine_names)}\")"
      ],
      "metadata": {
        "id": "Lzr-cQC7qWJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.字體加粗無ROI"
      ],
      "metadata": {
        "id": "tp5CEMysrdiZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rf_predict_handwrite_folder_2(folder_path, rf_model, img_size=(16, 16)):\n",
        "\n",
        "    X_flat, names = load_handwrite_enhanced(folder_path, img_size=img_size)  # (N, 256)\n",
        "\n",
        "    # 用 RF 做分類\n",
        "    y_pred = rf_model.predict(X_flat)\n",
        "\n",
        "    if hasattr(rf_model, \"predict_proba\"):\n",
        "        proba = rf_model.predict_proba(X_flat)          # (N, n_classes)\n",
        "        max_probs = proba.max(axis=1)                   # (N,)\n",
        "    else:\n",
        "        max_probs = np.full(len(y_pred), np.nan)\n",
        "\n",
        "    return names, y_pred, max_probs\n"
      ],
      "metadata": {
        "id": "P9bLpmq6sMXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"使用 RandomForest 分類器，對字加粗手寫資料預測\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# 1) 醫師的手寫（handwrite/dr）\n",
        "dr_names, dr_preds_rf, dr_conf_rf = rf_predict_handwrite_folder_2(\n",
        "    'handwrite/dr',\n",
        "    rf_model,\n",
        "    img_size=(16, 16)\n",
        ")\n",
        "\n",
        "print(\"\\n=== handwrite/dr 預測結果 (RandomForest) ===\")\n",
        "for name, pred, conf in zip(dr_names, dr_preds_rf, dr_conf_rf):\n",
        "    print(f\"檔名: {name:>6s} -> 預測數字: {pred} (confidence: {conf:.3f})\")\n",
        "\n",
        "# 2) 我的手寫（handwrite/mine）\n",
        "mine_names, mine_preds_rf, mine_conf_rf = rf_predict_handwrite_folder_2(\n",
        "    'handwrite/mine',\n",
        "    rf_model,\n",
        "    img_size=(16, 16)\n",
        ")\n",
        "\n",
        "print(\"\\n=== handwrite/mine 預測結果 (RandomForest) ===\")\n",
        "for name, pred, conf in zip(mine_names, mine_preds_rf, mine_conf_rf):\n",
        "    print(f\"檔名: {name:>6s} -> 預測數字: {pred} (confidence: {conf:.3f})\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CtoP2WBtsMXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dr_correct = sum(\n",
        "    int(name.split('.')[0]) == int(pred)\n",
        "    for name, pred in zip(dr_names, dr_preds_rf)\n",
        ")\n",
        "print(f\"\\ndr 正確 {dr_correct} / {len(dr_names)}\")\n",
        "\n",
        "mine_correct = sum(\n",
        "    int(name.split('.')[0]) == int(pred)\n",
        "    for name, pred in zip(mine_names, mine_preds_rf)\n",
        ")\n",
        "print(f\"mine 正確 {mine_correct} / {len(mine_names)}\")"
      ],
      "metadata": {
        "id": "Y6C_MuTPsMXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.字體加粗+ROI"
      ],
      "metadata": {
        "id": "CWPhhYOXsrma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rf_predict_handwrite_folder_3(folder_path, rf_model, img_size=(16, 16)):\n",
        "\n",
        "    X_flat, names = load_handwrite_enhanced_ROI(folder_path, img_size=img_size)  # (N, 256)\n",
        "\n",
        "    # 用 RF 做分類\n",
        "    y_pred = rf_model.predict(X_flat)\n",
        "\n",
        "    if hasattr(rf_model, \"predict_proba\"):\n",
        "        proba = rf_model.predict_proba(X_flat)          # (N, n_classes)\n",
        "        max_probs = proba.max(axis=1)                   # (N,)\n",
        "    else:\n",
        "        max_probs = np.full(len(y_pred), np.nan)\n",
        "\n",
        "    return names, y_pred, max_probs\n"
      ],
      "metadata": {
        "id": "ZnscRlk4swh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"使用 RandomForest 分類器，對字加粗+ROI手寫資料預測\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# 1) 醫師的手寫（handwrite/dr）\n",
        "dr_names, dr_preds_rf, dr_conf_rf = rf_predict_handwrite_folder_3(\n",
        "    'handwrite/dr',\n",
        "    rf_model,\n",
        "    img_size=(16, 16)\n",
        ")\n",
        "\n",
        "print(\"\\n=== handwrite/dr 預測結果 (RandomForest) ===\")\n",
        "for name, pred, conf in zip(dr_names, dr_preds_rf, dr_conf_rf):\n",
        "    print(f\"檔名: {name:>6s} -> 預測數字: {pred} (confidence: {conf:.3f})\")\n",
        "\n",
        "# 2) 我的手寫（handwrite/mine）\n",
        "mine_names, mine_preds_rf, mine_conf_rf = rf_predict_handwrite_folder_3(\n",
        "    'handwrite/mine',\n",
        "    rf_model,\n",
        "    img_size=(16, 16)\n",
        ")\n",
        "\n",
        "print(\"\\n=== handwrite/mine 預測結果 (RandomForest) ===\")\n",
        "for name, pred, conf in zip(mine_names, mine_preds_rf, mine_conf_rf):\n",
        "    print(f\"檔名: {name:>6s} -> 預測數字: {pred} (confidence: {conf:.3f})\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "z1jfqZb-swh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dr_correct = sum(\n",
        "    int(name.split('.')[0]) == int(pred)\n",
        "    for name, pred in zip(dr_names, dr_preds_rf)\n",
        ")\n",
        "print(f\"\\ndr 正確 {dr_correct} / {len(dr_names)}\")\n",
        "\n",
        "mine_correct = sum(\n",
        "    int(name.split('.')[0]) == int(pred)\n",
        "    for name, pred in zip(mine_names, mine_preds_rf)\n",
        ")\n",
        "print(f\"mine 正確 {mine_correct} / {len(mine_names)}\")"
      ],
      "metadata": {
        "id": "SNqKEhriswiA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 方法五:XGBooster\n"
      ],
      "metadata": {
        "id": "_8R4GEsQAE3w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "IMG_SIZE   = (16, 16)\n",
        "TRAIN_PATH = 'usps_inverted/train'\n",
        "TEST_PATH  = 'usps_inverted/test'\n",
        "\n",
        "\n",
        "def train_usps_xgboost(\n",
        "    n_estimators=300,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.1,\n",
        "    subsample=0.9,\n",
        "    colsample_bytree=0.9,\n",
        "    random_state=42\n",
        "):\n",
        "    # 1. 載入 USPS train / test\n",
        "    X_train_imgs, y_train = load_usps_split(TRAIN_PATH, img_size=IMG_SIZE)\n",
        "    X_test_imgs,  y_test  = load_usps_split(TEST_PATH,  img_size=IMG_SIZE)\n",
        "\n",
        "    # 2. 攤平成向量 (N, 256)\n",
        "    H, W = IMG_SIZE\n",
        "    D = H * W\n",
        "\n",
        "    X_train = X_train_imgs.reshape(X_train_imgs.shape[0], D)\n",
        "    X_test  = X_test_imgs.reshape(X_test_imgs.shape[0],  D)\n",
        "\n",
        "    print(\"Train shape :\", X_train.shape)\n",
        "    print(\"Test  shape :\", X_test.shape)\n",
        "\n",
        "    # 3. 建立 XGBoost 分類器\n",
        "    xgb = XGBClassifier(\n",
        "        n_estimators=n_estimators,\n",
        "        max_depth=max_depth,\n",
        "        learning_rate=learning_rate,\n",
        "        subsample=subsample,\n",
        "        colsample_bytree=colsample_bytree,\n",
        "        objective='multi:softmax',\n",
        "        num_class=10,\n",
        "        tree_method='hist',\n",
        "        random_state=random_state,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    # 4. 訓練\n",
        "    print(\"\\n開始訓練 USPS XGBoostClassifier ...\")\n",
        "    xgb.fit(X_train, y_train)\n",
        "    print(\"訓練完成！\")\n",
        "\n",
        "    # 5. 在 USPS test set 上評估\n",
        "    y_pred = xgb.predict(X_test)\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    print(\"\\n=== XGBoost 在 USPS 的表現 ===\")\n",
        "    print(\"Accuracy:\", acc)\n",
        "\n",
        "    print(\"\\n分類報告：\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    print(\"Confusion Matrix：\")\n",
        "    print(cm)\n",
        "\n",
        "    return xgb, X_test_imgs, y_test\n"
      ],
      "metadata": {
        "id": "-b6xchKVAINs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_model, X_test_imgs, y_test = train_usps_xgboost()\n"
      ],
      "metadata": {
        "id": "5_JBN0ojAI6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##方法五:XGBooster_自己手寫預測"
      ],
      "metadata": {
        "id": "Ecy6S7egpz3j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.手寫字_原始版(無框ROI+無字體加粗)\n"
      ],
      "metadata": {
        "id": "JKr59s5Xu6pQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def xgb_predict_handwrite_folder(folder_path, xgb_model, img_size=(16, 16)):\n",
        "    X_flat, names = load_handwrite_original(folder_path, img_size=img_size)  # (N, 256)\n",
        "    y_pred = xgb_model.predict(X_flat)\n",
        "    return names, y_pred\n"
      ],
      "metadata": {
        "id": "554tXCl1vW0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"使用 XGBoost 分類器，對手寫資料重新預測\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# 1) 醫師的手寫（handwrite/dr）\n",
        "dr_names, dr_preds_xgb = xgb_predict_handwrite_folder(\n",
        "    'handwrite/dr',\n",
        "    xgb_model,\n",
        "    img_size=(16, 16)\n",
        ")\n",
        "\n",
        "print(\"\\n=== handwrite/dr 預測結果 (XGBoost) ===\")\n",
        "for name, pred in zip(dr_names, dr_preds_xgb):\n",
        "    print(f\"檔名: {name:>6s} -> 預測數字: {pred}\")\n",
        "\n",
        "# 2) 我的手寫（handwrite/mine）\n",
        "mine_names, mine_preds_xgb = xgb_predict_handwrite_folder(\n",
        "    'handwrite/mine',\n",
        "    xgb_model,\n",
        "    img_size=(16, 16)\n",
        ")\n",
        "\n",
        "print(\"\\n=== handwrite/mine 預測結果 (XGBoost) ===\")\n",
        "for name, pred in zip(mine_names, mine_preds_xgb):\n",
        "    print(f\"檔名: {name:>6s} -> 預測數字: {pred}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "IIzHDcemvenE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dr_correct = sum(\n",
        "    int(name.split('.')[0]) == int(pred)\n",
        "    for name, pred in zip(dr_names, dr_preds_xgb)\n",
        ")\n",
        "print(f\"\\ndr 正確 {dr_correct} / {len(dr_names)}\")\n",
        "\n",
        "mine_correct = sum(\n",
        "    int(name.split('.')[0]) == int(pred)\n",
        "    for name, pred in zip(mine_names, mine_preds_xgb)\n",
        ")\n",
        "print(f\"mine 正確 {mine_correct} / {len(mine_names)}\")\n"
      ],
      "metadata": {
        "id": "huC-b_d5vekd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.手寫字_無框ROI+字體加粗\n"
      ],
      "metadata": {
        "id": "vUN3phfWvHxF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def xgb_predict_handwrite_folder_2(folder_path, xgb_model, img_size=(16, 16)):\n",
        "    X_flat, names = load_handwrite_enhanced(folder_path, img_size=img_size)  # (N, 256)\n",
        "    y_pred = xgb_model.predict(X_flat)\n",
        "    return names, y_pred\n"
      ],
      "metadata": {
        "id": "ouZeJLc6v7dW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"使用 XGBoost 分類器，對字加粗手寫資料重新預測\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# 1) 醫師的手寫（handwrite/dr）\n",
        "dr_names, dr_preds_xgb = xgb_predict_handwrite_folder_2(\n",
        "    'handwrite/dr',\n",
        "    xgb_model,\n",
        "    img_size=(16, 16)\n",
        ")\n",
        "\n",
        "print(\"\\n=== handwrite/dr 預測結果 (XGBoost) ===\")\n",
        "for name, pred in zip(dr_names, dr_preds_xgb):\n",
        "    print(f\"檔名: {name:>6s} -> 預測數字: {pred}\")\n",
        "\n",
        "# 2) 我的手寫（handwrite/mine）\n",
        "mine_names, mine_preds_xgb = xgb_predict_handwrite_folder_2(\n",
        "    'handwrite/mine',\n",
        "    xgb_model,\n",
        "    img_size=(16, 16)\n",
        ")\n",
        "print(\"\\n=== handwrite/mine 預測結果 (XGBoost) ===\")\n",
        "for name, pred in zip(mine_names, mine_preds_xgb):\n",
        "    print(f\"檔名: {name:>6s} -> 預測數字: {pred}\")"
      ],
      "metadata": {
        "id": "dY_0Ue00v7dW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dr_correct = sum(\n",
        "    int(name.split('.')[0]) == int(pred)\n",
        "    for name, pred in zip(dr_names, dr_preds_xgb)\n",
        ")\n",
        "print(f\"\\ndr 正確 {dr_correct} / {len(dr_names)}\")\n",
        "\n",
        "mine_correct = sum(\n",
        "    int(name.split('.')[0]) == int(pred)\n",
        "    for name, pred in zip(mine_names, mine_preds_xgb)\n",
        ")\n",
        "print(f\"mine 正確 {mine_correct} / {len(mine_names)}\")\n"
      ],
      "metadata": {
        "id": "nUoY5jLYv7dW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.手寫字_ROI+字體加粗\n"
      ],
      "metadata": {
        "id": "zScRF9FHvIAH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def xgb_predict_handwrite_folder_3(folder_path, xgb_model, img_size=(16, 16)):\n",
        "    X_flat, names = load_handwrite_enhanced_ROI(folder_path, img_size=img_size)  # (N, 256)\n",
        "    y_pred = xgb_model.predict(X_flat)\n",
        "    return names, y_pred\n"
      ],
      "metadata": {
        "id": "IISI28ClwRK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"使用 XGBoost 分類器，對字加粗+ROI手寫資料重新預測\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# 1) 醫師的手寫（handwrite/dr）\n",
        "dr_names, dr_preds_xgb = xgb_predict_handwrite_folder_3(\n",
        "    'handwrite/dr',\n",
        "    xgb_model,\n",
        "    img_size=(16, 16)\n",
        ")\n",
        "\n",
        "print(\"\\n=== handwrite/dr 預測結果 (XGBoost) ===\")\n",
        "for name, pred in zip(dr_names, dr_preds_xgb):\n",
        "    print(f\"檔名: {name:>6s} -> 預測數字: {pred}\")\n",
        "\n",
        "# 2) 我的手寫（handwrite/mine）\n",
        "mine_names, mine_preds_xgb = xgb_predict_handwrite_folder_3(\n",
        "    'handwrite/mine',\n",
        "    xgb_model,\n",
        "    img_size=(16, 16)\n",
        ")\n",
        "print(\"\\n=== handwrite/mine 預測結果 (XGBoost) ===\")\n",
        "for name, pred in zip(mine_names, mine_preds_xgb):\n",
        "    print(f\"檔名: {name:>6s} -> 預測數字: {pred}\")"
      ],
      "metadata": {
        "id": "K9mXMTH0wRK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dr_correct = sum(\n",
        "    int(name.split('.')[0]) == int(pred)\n",
        "    for name, pred in zip(dr_names, dr_preds_xgb)\n",
        ")\n",
        "print(f\"\\ndr 正確 {dr_correct} / {len(dr_names)}\")\n",
        "\n",
        "mine_correct = sum(\n",
        "    int(name.split('.')[0]) == int(pred)\n",
        "    for name, pred in zip(mine_names, mine_preds_xgb)\n",
        ")\n",
        "print(f\"mine 正確 {mine_correct} / {len(mine_names)}\")\n"
      ],
      "metadata": {
        "id": "ufJE0NSYwRK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##方法六 :Support Vector Machine"
      ],
      "metadata": {
        "id": "k3m_aaxEBClg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "IMG_SIZE   = (16, 16)\n",
        "TRAIN_PATH = 'usps_inverted/train'\n",
        "TEST_PATH  = 'usps_inverted/test'\n",
        "\n",
        "def train_usps_svm(\n",
        "    C=10.0,\n",
        "    kernel='rbf',\n",
        "    gamma='scale',\n",
        "    random_state=42\n",
        "):\n",
        "    # 1. 載入 USPS train / test\n",
        "    X_train_imgs, y_train = load_usps_split(TRAIN_PATH, img_size=IMG_SIZE)\n",
        "    X_test_imgs,  y_test  = load_usps_split(TEST_PATH,  img_size=IMG_SIZE)\n",
        "\n",
        "    # 2. 攤平成向量 (N, 256)\n",
        "    H, W = IMG_SIZE\n",
        "    D = H * W\n",
        "\n",
        "    X_train = X_train_imgs.reshape(X_train_imgs.shape[0], D)\n",
        "    X_test  = X_test_imgs.reshape(X_test_imgs.shape[0],  D)\n",
        "\n",
        "    print(\"Train shape :\", X_train.shape)\n",
        "    print(\"Test  shape :\", X_test.shape)\n",
        "\n",
        "    # 3. 建立 SVM 分類器\n",
        "    #    這裡用 RBF kernel\n",
        "    svm = SVC(\n",
        "        C=C,\n",
        "        kernel=kernel,\n",
        "        gamma=gamma,\n",
        "        random_state=random_state\n",
        "    )\n",
        "\n",
        "    # 4. 訓練\n",
        "    print(\"\\n開始訓練 USPS SVM 分類器\")\n",
        "    svm.fit(X_train, y_train)\n",
        "    print(\"訓練完成！\")\n",
        "\n",
        "    # 5. 在 USPS test set 上評估\n",
        "    y_pred = svm.predict(X_test)\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    print(\"\\n=== SVM 在 USPS 的表現 ===\")\n",
        "    print(\"Accuracy:\", acc)\n",
        "\n",
        "    print(\"\\n分類報告：\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    print(\"Confusion Matrix：\")\n",
        "    print(cm)\n",
        "\n",
        "    # 回傳 model + 測試資料（如果你之後還想拿來畫圖用）\n",
        "    return svm, X_test_imgs, y_test\n",
        "svm_model, X_test_imgs, y_test = train_usps_svm()\n"
      ],
      "metadata": {
        "id": "lDGuMwrABZs3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##方法六 :Support Vector Machine_自己手寫預測"
      ],
      "metadata": {
        "id": "w9gp_FLeqA76"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.手寫字_原始版(無框ROI+無字體加粗)\n"
      ],
      "metadata": {
        "id": "usaQzZNavQ_C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def svm_predict_handwrite_folder(folder_path, svm_model, img_size=(16, 16)):\n",
        "    # 使用原本的前處理\n",
        "    X_flat, names = load_handwrite_original(folder_path, img_size=img_size)  # (N, 256)\n",
        "    y_pred = svm_model.predict(X_flat)\n",
        "\n",
        "    return names, y_pred\n"
      ],
      "metadata": {
        "id": "PXTTe5LKxD_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"使用 SVM 分類器，對手寫資料預測\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# 1) 醫師的手寫（handwrite/dr）\n",
        "dr_names, dr_preds_svm = svm_predict_handwrite_folder(\n",
        "    'handwrite/dr',\n",
        "    svm_model,\n",
        "    img_size=(16, 16)\n",
        ")\n",
        "\n",
        "print(\"\\n=== handwrite/dr 預測結果 (SVM) ===\")\n",
        "for name, pred in zip(dr_names, dr_preds_svm):\n",
        "    print(f\"檔名: {name:>6s} -> 預測數字: {pred}\")\n",
        "\n",
        "# 2) 我的手寫（handwrite/mine）\n",
        "mine_names, mine_preds_svm = svm_predict_handwrite_folder(\n",
        "    'handwrite/mine',\n",
        "    svm_model,\n",
        "    img_size=(16, 16)\n",
        ")\n",
        "\n",
        "print(\"\\n=== handwrite/mine 預測結果 (SVM) ===\")\n",
        "for name, pred in zip(mine_names, mine_preds_svm):\n",
        "    print(f\"檔名: {name:>6s} -> 預測數字: {pred}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "jjIChitsxD7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dr_correct = sum(\n",
        "    int(name.split('.')[0]) == int(pred)\n",
        "    for name, pred in zip(dr_names, dr_preds_svm)\n",
        ")\n",
        "print(f\"\\ndr 正確 {dr_correct} / {len(dr_names)}\")\n",
        "\n",
        "mine_correct = sum(\n",
        "    int(name.split('.')[0]) == int(pred)\n",
        "    for name, pred in zip(mine_names, mine_preds_svm)\n",
        ")\n",
        "print(f\"mine 正確 {mine_correct} / {len(mine_names)}\")\n"
      ],
      "metadata": {
        "id": "JOA5xoZkxD2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.手寫字_無框ROI+字體加粗\n"
      ],
      "metadata": {
        "id": "XdBKcNDhvQ_D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def svm_predict_handwrite_folder_2(folder_path, svm_model, img_size=(16, 16)):\n",
        "    X_flat, names = load_handwrite_enhanced(folder_path, img_size=img_size)  # (N, 256)\n",
        "    y_pred = svm_model.predict(X_flat)\n",
        "\n",
        "    return names, y_pred\n"
      ],
      "metadata": {
        "id": "3YJ4IFfUyZ3w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"使用 SVM 分類器，對字加粗手寫資料預測\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# 1) 醫師的手寫（handwrite/dr）\n",
        "dr_names, dr_preds_svm = svm_predict_handwrite_folder_2(\n",
        "    'handwrite/dr',\n",
        "    svm_model,\n",
        "    img_size=(16, 16)\n",
        ")\n",
        "\n",
        "print(\"\\n=== handwrite/dr 預測結果 (SVM) ===\")\n",
        "for name, pred in zip(dr_names, dr_preds_svm):\n",
        "    print(f\"檔名: {name:>6s} -> 預測數字: {pred}\")\n",
        "\n",
        "# 2) 我的手寫（handwrite/mine）\n",
        "mine_names, mine_preds_svm = svm_predict_handwrite_folder_2(\n",
        "    'handwrite/mine',\n",
        "    svm_model,\n",
        "    img_size=(16, 16)\n",
        ")\n",
        "\n",
        "print(\"\\n=== handwrite/mine 預測結果 (SVM) ===\")\n",
        "for name, pred in zip(mine_names, mine_preds_svm):\n",
        "    print(f\"檔名: {name:>6s} -> 預測數字: {pred}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "N-dGBptnyZ3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dr_correct = sum(\n",
        "    int(name.split('.')[0]) == int(pred)\n",
        "    for name, pred in zip(dr_names, dr_preds_svm)\n",
        ")\n",
        "print(f\"\\ndr 正確 {dr_correct} / {len(dr_names)}\")\n",
        "\n",
        "mine_correct = sum(\n",
        "    int(name.split('.')[0]) == int(pred)\n",
        "    for name, pred in zip(mine_names, mine_preds_svm)\n",
        ")\n",
        "print(f\"mine 正確 {mine_correct} / {len(mine_names)}\")\n"
      ],
      "metadata": {
        "id": "p9gpdbK7yZ3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.手寫字_ROI+字體加粗\n"
      ],
      "metadata": {
        "id": "TTu4xLWTvQ_D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def svm_predict_handwrite_folder_3(folder_path, svm_model, img_size=(16, 16)):\n",
        "    X_flat, names = load_handwrite_enhanced_ROI(folder_path, img_size=img_size)  # (N, 256)\n",
        "    y_pred = svm_model.predict(X_flat)\n",
        "\n",
        "    return names, y_pred\n"
      ],
      "metadata": {
        "id": "bvXid4OfybEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"使用 SVM 分類器，對字加粗+ROI手寫資料預測\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# 1) 醫師的手寫（handwrite/dr）\n",
        "dr_names, dr_preds_svm = svm_predict_handwrite_folder_3(\n",
        "    'handwrite/dr',\n",
        "    svm_model,\n",
        "    img_size=(16, 16)\n",
        ")\n",
        "\n",
        "print(\"\\n=== handwrite/dr 預測結果 (SVM) ===\")\n",
        "for name, pred in zip(dr_names, dr_preds_svm):\n",
        "    print(f\"檔名: {name:>6s} -> 預測數字: {pred}\")\n",
        "\n",
        "# 2) 我的手寫（handwrite/mine）\n",
        "mine_names, mine_preds_svm = svm_predict_handwrite_folder_3(\n",
        "    'handwrite/mine',\n",
        "    svm_model,\n",
        "    img_size=(16, 16)\n",
        ")\n",
        "\n",
        "print(\"\\n=== handwrite/mine 預測結果 (SVM) ===\")\n",
        "for name, pred in zip(mine_names, mine_preds_svm):\n",
        "    print(f\"檔名: {name:>6s} -> 預測數字: {pred}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "M9c6n2oiybEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dr_correct = sum(\n",
        "    int(name.split('.')[0]) == int(pred)\n",
        "    for name, pred in zip(dr_names, dr_preds_svm)\n",
        ")\n",
        "print(f\"\\ndr 正確 {dr_correct} / {len(dr_names)}\")\n",
        "\n",
        "mine_correct = sum(\n",
        "    int(name.split('.')[0]) == int(pred)\n",
        "    for name, pred in zip(mine_names, mine_preds_svm)\n",
        ")\n",
        "print(f\"mine 正確 {mine_correct} / {len(mine_names)}\")\n"
      ],
      "metadata": {
        "id": "Iwon1RfIybEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 方法七:CNN"
      ],
      "metadata": {
        "id": "vTje2XKSCp7r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, BatchNormalization\n",
        "\n",
        "def build_cnn_with_bn(input_shape=(16,16,1)):\n",
        "    model = Sequential()\n",
        "\n",
        "    # conv block 1\n",
        "    model.add(Conv2D(16, (5,5), padding='same', activation='relu',\n",
        "                     input_shape=input_shape))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "    # conv block 2\n",
        "    model.add(Conv2D(36, (5,5), padding='same', activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "Vvu2Ei4kzn_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "def train_usps_cnn_bn_aug(batch_size=64, epochs=50, verbose=1):\n",
        "    # 1. 載入 USPS\n",
        "    X_train_imgs, y_train = load_usps_split(TRAIN_PATH, img_size=IMG_SIZE)\n",
        "    X_test_imgs,  y_test  = load_usps_split(TEST_PATH,  img_size=IMG_SIZE)\n",
        "\n",
        "    X_train = X_train_imgs[..., np.newaxis]   # (N,16,16,1)\n",
        "    X_test  = X_test_imgs[...,  np.newaxis]\n",
        "\n",
        "    print(\"Train shape:\", X_train.shape)\n",
        "    print(\"Test  shape:\", X_test.shape)\n",
        "\n",
        "    # 2. 建立 CNN+BN（就是前面那個 build_cnn_with_bn）\n",
        "    model = build_cnn_with_bn(input_shape=(16,16,1))\n",
        "    model.summary()\n",
        "\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    # 3. 輕量 data augmentation（不要太大，16x16 很容易壞掉）\n",
        "    datagen = ImageDataGenerator(\n",
        "        rotation_range=10,      # ±10° 小旋轉\n",
        "        width_shift_range=0.1,  # 左右平移 10%\n",
        "        height_shift_range=0.1, # 上下平移 10%\n",
        "        zoom_range=0.1          # 輕微縮放\n",
        "    )\n",
        "    datagen.fit(X_train)\n",
        "\n",
        "    # 4. LR schedule + EarlyStopping\n",
        "    cb_lr = ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.5,\n",
        "        patience=3,\n",
        "        min_lr=1e-5,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    cb_es = EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=8,\n",
        "        restore_best_weights=True,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    steps_per_epoch = len(X_train) // batch_size\n",
        "\n",
        "    history = model.fit(\n",
        "        datagen.flow(X_train, y_train, batch_size=batch_size),\n",
        "        steps_per_epoch=steps_per_epoch,\n",
        "        epochs=epochs,\n",
        "        validation_data=(X_test, y_test),\n",
        "        callbacks=[cb_lr, cb_es],\n",
        "        verbose=verbose\n",
        "    )\n",
        "\n",
        "    # 5. 評估\n",
        "    test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "    print(f\"\\nCNN+BN+aug – Keras evaluate accuracy: {test_acc}\")\n",
        "\n",
        "    y_pred_probs = model.predict(X_test, verbose=0)\n",
        "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    print(\"Sklearn accuracy:\", acc)\n",
        "\n",
        "    print(\"\\n分類報告：\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print(\"Confusion Matrix：\")\n",
        "    print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "    return model, history, X_test_imgs, y_test\n"
      ],
      "metadata": {
        "id": "wNNAoQ9bIEr4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model, cnn_history, X_test_imgs, y_test = train_usps_cnn_bn_aug(\n",
        "    batch_size=64,\n",
        "    epochs=50,\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "id": "y-iP9DclIEo4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 方法七:CNN_自己手寫預測"
      ],
      "metadata": {
        "id": "rydz5svIqQIA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.手寫字_原始版(無框ROI+無字體加粗)\n"
      ],
      "metadata": {
        "id": "gb9ByPTKvS5d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cnn_predict_handwrite_folder(folder_path, cnn_model, img_size=(16, 16)):\n",
        "\n",
        "    X_flat, names = load_handwrite_original(folder_path, img_size=img_size)  # (N, 256)\n",
        "\n",
        "    H, W = img_size\n",
        "    # 還原成 CNN 要的 shape: (N, 16, 16, 1)\n",
        "    X_imgs = X_flat.reshape(-1, H, W, 1).astype(\"float32\")\n",
        "\n",
        "    # 丟進 CNN 做預測\n",
        "    y_pred_probs = cnn_model.predict(X_imgs, verbose=0)   # (N, 10)\n",
        "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "    max_probs = y_pred_probs.max(axis=1)\n",
        "\n",
        "    return names, y_pred, max_probs\n"
      ],
      "metadata": {
        "id": "UB9QB9au1CXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"使用 CNN+BN+Aug 分類器，對手寫資料預測\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# 1) 醫師的手寫（handwrite/dr）\n",
        "dr_names, dr_preds_cnn, dr_conf_cnn = cnn_predict_handwrite_folder(\n",
        "    'handwrite/dr',\n",
        "    cnn_model,\n",
        "    img_size=(16, 16)\n",
        ")\n",
        "\n",
        "print(\"\\n=== handwrite/dr 預測結果 (CNN) ===\")\n",
        "for name, pred, conf in zip(dr_names, dr_preds_cnn, dr_conf_cnn):\n",
        "    print(f\"檔名: {name:>6s} -> 預測數字: {pred} (confidence: {conf:.3f})\")\n",
        "\n",
        "# 2) 我的手寫（handwrite/mine）\n",
        "mine_names, mine_preds_cnn, mine_conf_cnn = cnn_predict_handwrite_folder(\n",
        "    'handwrite/mine',\n",
        "    cnn_model,\n",
        "    img_size=(16, 16)\n",
        ")\n",
        "\n",
        "print(\"\\n=== handwrite/mine 預測結果 (CNN) ===\")\n",
        "for name, pred, conf in zip(mine_names, mine_preds_cnn, mine_conf_cnn):\n",
        "    print(f\"檔名: {name:>6s} -> 預測數字: {pred} (confidence: {conf:.3f})\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sulx2jUM1CUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dr_correct = sum(\n",
        "    int(name.split('.')[0]) == int(pred)\n",
        "    for name, pred in zip(dr_names, dr_preds_cnn)\n",
        ")\n",
        "print(f\"\\ndr 正確 {dr_correct} / {len(dr_names)}\")\n",
        "\n",
        "mine_correct = sum(\n",
        "    int(name.split('.')[0]) == int(pred)\n",
        "    for name, pred in zip(mine_names, mine_preds_cnn)\n",
        ")\n",
        "print(f\"mine 正確 {mine_correct} / {len(mine_names)}\")"
      ],
      "metadata": {
        "id": "DZg_J9MX1CQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.手寫字_無框ROI+字體加粗\n"
      ],
      "metadata": {
        "id": "AWrWJRPqvS5e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cnn_predict_handwrite_folder_2(folder_path, cnn_model, img_size=(16, 16)):\n",
        "\n",
        "    X_flat, names = load_handwrite_enhanced(folder_path, img_size=img_size)  # (N, 256)\n",
        "\n",
        "    H, W = img_size\n",
        "    # 還原成 CNN 要的 shape: (N, 16, 16, 1)\n",
        "    X_imgs = X_flat.reshape(-1, H, W, 1).astype(\"float32\")\n",
        "\n",
        "    # 丟進 CNN 做預測\n",
        "    y_pred_probs = cnn_model.predict(X_imgs, verbose=0)   # (N, 10)\n",
        "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "    max_probs = y_pred_probs.max(axis=1)\n",
        "\n",
        "    return names, y_pred, max_probs\n"
      ],
      "metadata": {
        "id": "4s9s12As1We-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"使用 CNN+BN+Aug 分類器，對字加粗手寫資料預測\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# 1) 醫師的手寫（handwrite/dr）\n",
        "dr_names, dr_preds_cnn, dr_conf_cnn = cnn_predict_handwrite_folder_2(\n",
        "    'handwrite/dr',\n",
        "    cnn_model,\n",
        "    img_size=(16, 16)\n",
        ")\n",
        "\n",
        "print(\"\\n=== handwrite/dr 預測結果 (CNN) ===\")\n",
        "for name, pred, conf in zip(dr_names, dr_preds_cnn, dr_conf_cnn):\n",
        "    print(f\"檔名: {name:>6s} -> 預測數字: {pred} (confidence: {conf:.3f})\")\n",
        "\n",
        "# 2) 我的手寫（handwrite/mine）\n",
        "mine_names, mine_preds_cnn, mine_conf_cnn = cnn_predict_handwrite_folder_2(\n",
        "    'handwrite/mine',\n",
        "    cnn_model,\n",
        "    img_size=(16, 16)\n",
        ")\n",
        "\n",
        "print(\"\\n=== handwrite/mine 預測結果 (CNN) ===\")\n",
        "for name, pred, conf in zip(mine_names, mine_preds_cnn, mine_conf_cnn):\n",
        "    print(f\"檔名: {name:>6s} -> 預測數字: {pred} (confidence: {conf:.3f})\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oX559AsM1We_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dr_correct = sum(\n",
        "    int(name.split('.')[0]) == int(pred)\n",
        "    for name, pred in zip(dr_names, dr_preds_cnn)\n",
        ")\n",
        "print(f\"\\ndr 正確 {dr_correct} / {len(dr_names)}\")\n",
        "\n",
        "mine_correct = sum(\n",
        "    int(name.split('.')[0]) == int(pred)\n",
        "    for name, pred in zip(mine_names, mine_preds_cnn)\n",
        ")\n",
        "print(f\"mine 正確 {mine_correct} / {len(mine_names)}\")"
      ],
      "metadata": {
        "id": "-FVasJD31We_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.手寫字_ROI+字體加粗\n"
      ],
      "metadata": {
        "id": "a6IirxdDvS5e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cnn_predict_handwrite_folder_3(folder_path, cnn_model, img_size=(16, 16)):\n",
        "\n",
        "    X_flat, names = load_handwrite_enhanced_ROI(folder_path, img_size=img_size)  # (N, 256)\n",
        "\n",
        "    H, W = img_size\n",
        "    # 還原成 CNN 要的 shape: (N, 16, 16, 1)\n",
        "    X_imgs = X_flat.reshape(-1, H, W, 1).astype(\"float32\")\n",
        "\n",
        "    # 丟進 CNN 做預測\n",
        "    y_pred_probs = cnn_model.predict(X_imgs, verbose=0)   # (N, 10)\n",
        "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "    max_probs = y_pred_probs.max(axis=1)\n",
        "\n",
        "    return names, y_pred, max_probs\n"
      ],
      "metadata": {
        "id": "FKjCfD831XgB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"使用 CNN+BN+Aug 分類器，對字加粗+ROI手寫資料預測\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# 1) 醫師的手寫（handwrite/dr）\n",
        "dr_names, dr_preds_cnn, dr_conf_cnn = cnn_predict_handwrite_folder_3(\n",
        "    'handwrite/dr',\n",
        "    cnn_model,\n",
        "    img_size=(16, 16)\n",
        ")\n",
        "\n",
        "print(\"\\n=== handwrite/dr 預測結果 (CNN) ===\")\n",
        "for name, pred, conf in zip(dr_names, dr_preds_cnn, dr_conf_cnn):\n",
        "    print(f\"檔名: {name:>6s} -> 預測數字: {pred} (confidence: {conf:.3f})\")\n",
        "\n",
        "# 2) 我的手寫（handwrite/mine）\n",
        "mine_names, mine_preds_cnn, mine_conf_cnn = cnn_predict_handwrite_folder_3(\n",
        "    'handwrite/mine',\n",
        "    cnn_model,\n",
        "    img_size=(16, 16)\n",
        ")\n",
        "\n",
        "print(\"\\n=== handwrite/mine 預測結果 (CNN) ===\")\n",
        "for name, pred, conf in zip(mine_names, mine_preds_cnn, mine_conf_cnn):\n",
        "    print(f\"檔名: {name:>6s} -> 預測數字: {pred} (confidence: {conf:.3f})\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "C636wNhf1XgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dr_correct = sum(\n",
        "    int(name.split('.')[0]) == int(pred)\n",
        "    for name, pred in zip(dr_names, dr_preds_cnn)\n",
        ")\n",
        "print(f\"\\ndr 正確 {dr_correct} / {len(dr_names)}\")\n",
        "\n",
        "mine_correct = sum(\n",
        "    int(name.split('.')[0]) == int(pred)\n",
        "    for name, pred in zip(mine_names, mine_preds_cnn)\n",
        ")\n",
        "print(f\"mine 正確 {mine_correct} / {len(mine_names)}\")"
      ],
      "metadata": {
        "id": "j41a-6n11XgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# 數據輸入\n",
        "classifiers = ['Mean', 'SVD', 'HOSVD', 'Random Forest', 'XGBoost', 'SVM', 'CNN']\n",
        "\n",
        "data = {\n",
        "    'USPS Testsets': [0.8142, 0.9471, 0.9432, 0.9407, 0.9382, 0.9526, 0.9745],\n",
        "    'Original (Dr\\'s)': [0.3, 0.4, 0.6, 0.1, 0.2, 0.3, 0.4],\n",
        "    'Original (Mine)': [0.3, 0.5, 0.8, 0.2, 0.2, 0.5, 0.6],\n",
        "    'Bold (Dr\\'s)': [0.7, 0.9, 0.8, 0.4, 0.4, 0.9, 0.9],\n",
        "    'Bold (Mine)': [0.8, 1, 1, 0.4, 0.6, 0.9, 0.9],\n",
        "    'ROI+Bold (Dr\\'s)': [0.3, 0.8, 0.7, 0.3, 0.4, 0.6, 1],\n",
        "    'ROI+Bold (Mine)': [0.8, 0.8, 0.6, 0.4, 0.4, 0.7, 0.9]\n",
        "}\n",
        "\n",
        "# 設定圖表大小\n",
        "plt.figure(figsize=(12, 7))\n",
        "\n",
        "# 定義顏色和線條樣式以區分\n",
        "styles = ['-', '--', '-.', ':']\n",
        "markers = ['o', 's', '^', 'D', 'v', '<', '>']\n",
        "\n",
        "# 繪製每一條線\n",
        "for i, (label, values) in enumerate(data.items()):\n",
        "    plt.plot(classifiers, values,\n",
        "             marker=markers[i % len(markers)],\n",
        "             linestyle=styles[i % len(styles)],\n",
        "             linewidth=2,\n",
        "             label=label)\n",
        "\n",
        "# 圖表修飾\n",
        "plt.title('Comparison of Classifiers on Different Testsets', fontsize=16)\n",
        "plt.xlabel('Classifiers', fontsize=12)\n",
        "plt.ylabel('Accuracy', fontsize=12)\n",
        "plt.ylim(0, 1.1)  # 設定 Y 軸範圍\n",
        "plt.grid(True, linestyle='--', alpha=0.7)\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')  # 圖例放在外側以免擋住線條\n",
        "\n",
        "# 調整佈局避免文字被切掉\n",
        "plt.tight_layout()\n",
        "\n",
        "# 顯示圖表\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cpY5wOdFThDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UE0upi4LTht6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}